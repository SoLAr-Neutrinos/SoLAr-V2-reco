{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solarv2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "path_prefix = \"../../data/SoLAr_v2/\"\n",
    "charge_bucket = \"cosmics/root/\"\n",
    "light_bucket = \"root/46v_12db_th950_deco/\"\n",
    "\n",
    "input = \"deco_v3_0cd913fa_20230706_191437.data.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Load options\n",
    "params.reload_files = False\n",
    "params.rematch_events = False\n",
    "\n",
    "# Save options\n",
    "params.overwrite_metrics = True\n",
    "params.save_figures = True\n",
    "\n",
    "# Plotting options\n",
    "params.flip_x = True\n",
    "params.individual_plots = np.arange(1, 11, 1)\n",
    "params.show_figures = False\n",
    "params.label_font_size = 16\n",
    "params.tick_font_size = 16\n",
    "params.title_font_size = 18\n",
    "\n",
    "# Events to process\n",
    "params.event_list = None\n",
    "\n",
    "# Noisy Pixels\n",
    "params.channel_disable_list = [(7, (1, 2))]  # (chip, channel)\n",
    "\n",
    "# Light variable to consider\n",
    "params.light_variable = \"integral\"\n",
    "\n",
    "# Units for plot labels\n",
    "params.q_unit = \"e\"  # After applying charge_gain\n",
    "params.xy_unit = \"mm\"\n",
    "params.z_unit = \"mm\"\n",
    "params.time_unit = \"ns\"\n",
    "\n",
    "# Conversion factors\n",
    "params.detector_z = 300\n",
    "params.detector_x = 128\n",
    "params.detector_y = 160\n",
    "\n",
    "# DBSCAN parameters for charge clustering\n",
    "params.min_samples = 2\n",
    "params.xy_epsilon = 8  # 8 ideal\n",
    "params.z_epsilon = 8  # 8 ideal\n",
    "\n",
    "# RANSAC parameters for line fitting\n",
    "params.ransac_residual_threshold = 6  # 6 ideal for charge, 35 ideal for light\n",
    "params.ransac_max_trials = 1000\n",
    "params.ransac_min_samples = 2  # 2 ideal for charge, 3 ideal for light\n",
    "\n",
    "# Force parameters for cylinder\n",
    "params.force_dh = 30\n",
    "params.force_dr = None\n",
    "\n",
    "# Filters for post processing\n",
    "params.min_score = -1.0\n",
    "params.max_score = 1.0\n",
    "params.min_track_length = 30\n",
    "params.max_track_length = np.inf\n",
    "params.max_tracks = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.output_folder = \"_\".join(input.split(\"_\")[-2:]).split(\".\")[0]\n",
    "charge_timestamp = pd.to_datetime(params.output_folder, format=\"%Y%m%d_%H%M%S\").strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "light_file = path_prefix + \"Light/\" + light_bucket + input\n",
    "charge_file = path_prefix + \"Charge/\" + charge_bucket + f\"evd_self_trigger-packets-{charge_timestamp}_CEST_validated.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recal_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter calculators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File handing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If match dictionary already exists for this file label, load it\n",
    "temp_filename = f\"{params.output_folder}/match_dict_{params.output_folder}.json\"\n",
    "if not params.rematch_events and os.path.isfile(temp_filename):\n",
    "    with open(temp_filename, \"r\") as f:\n",
    "        match_dict = json.load(f)\n",
    "        match_dict = {int(key): value for key, value in match_dict.items()}\n",
    "\n",
    "    print(\"Match_dict loaded from file\")\n",
    "\n",
    "del temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_filename = f\"{params.output_folder}/charge_df_{params.output_folder}.bz2\"\n",
    "if not params.reload_files and os.path.isfile(temp_filename):\n",
    "    charge_df = pd.read_csv(temp_filename, index_col=0)\n",
    "    if not params.event_list is None:\n",
    "        charge_df = charge_df.loc[params.event_list.intersection(charge_df.index)]\n",
    "    # for column in :\n",
    "    charge_df[charge_df.columns[9:]] = charge_df[charge_df.columns[9:]].applymap(\n",
    "        lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    "    )\n",
    "else:\n",
    "    charge_df = load_charge(charge_file, events=params.event_list)\n",
    "\n",
    "del temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up charge dataframe\n",
    "\n",
    "# Remove events with negative charge hits and without light trigger\n",
    "charge_mask = (charge_df[\"event_hits_q\"].apply(tuple).explode().groupby(\"eventID\").min() > 0) * (\n",
    "    charge_df[\"trigID\"].apply(len) > 0\n",
    ")\n",
    "charge_df = charge_df[charge_mask]\n",
    "\n",
    "print(f\"Removed charge events: {charge_mask.count()-charge_mask.sum()}/{charge_mask.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If match dictionary already loaded, match loaded charge events to light events before loading light events.\n",
    "light_event_list = None\n",
    "if not match_dict == {}:\n",
    "    light_event_list = ak.flatten(\n",
    "        [match_dict.get(event, []) for event in charge_df.index if params.event_list is None or event in params.event_list]\n",
    "    )\n",
    "\n",
    "    print(f\"{len(light_event_list)} light events to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_filename = f\"{params.output_folder}/light_df_{params.output_folder}.bz2\"\n",
    "# Load light events using light_event_list if loaded via match dictionary\n",
    "if not params.reload_files and os.path.isfile(temp_filename):\n",
    "    light_df = pd.read_csv(temp_filename, index_col=0)\n",
    "    if not light_event_list is None:\n",
    "        light_df = light_df[light_df[\"event\"].isin(light_event_list)]\n",
    "\n",
    "else:\n",
    "    light_df = load_light(light_file, deco=\"deco\" in light_file, events=light_event_list)\n",
    "\n",
    "print(f\"{light_df['event'].nunique()} light events loaded.\")\n",
    "del temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up light dataframe\n",
    "\n",
    "# If match dictionary not yet loaded, create it\n",
    "if match_dict == {} or params.rematch_events:\n",
    "    match_dict, dt = match_events(charge_df, light_df, return_dt=True)\n",
    "\n",
    "    # Remove light events without charge event match\n",
    "    light_events = np.unique(ak.flatten(match_dict.values()))\n",
    "    light_df = light_df[light_df[\"event\"].isin(light_events)]\n",
    "\n",
    "    print(f\"Remaining light events with charge event match: {light_df['event'].nunique()}\")\n",
    "\n",
    "# Remove charge events without associated light event\n",
    "charge_df = charge_df.loc[match_dict.keys()]\n",
    "\n",
    "print(f\"Remaining charge events with light match: {len(charge_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip x axis according to flag\n",
    "\n",
    "charge_df[\"event_hits_x\"] = charge_df[\"event_hits_x\"].apply(lambda x: [np.power(-1, params.flip_x) * i for i in x])\n",
    "light_df[\"x\"] = light_df[\"x\"].apply(lambda x: np.power(-1, params.flip_x) * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(params.output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save files if all events were considered, i.e. event_list is None\n",
    "if params.event_list is None:\n",
    "    charge_df.to_csv(f\"{params.output_folder}/charge_df_{params.output_folder}.bz2\")\n",
    "    light_df.to_csv(f\"{params.output_folder}/light_df_{params.output_folder}.bz2\")\n",
    "    with open(f\"{params.output_folder}/match_dict_{params.output_folder}.json\", \"w\") as f:\n",
    "        json.dump(match_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters to JSON just in case\n",
    "params_to_json(f\"{params.output_folder}/reconstruction_parameters_{params.output_folder}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sipm_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trigger time distribution\")\n",
    "charge_df[\"trig_time\"].apply(np.mean).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Event duration in {params.time_unit}\")\n",
    "charge_df[\"event_duration\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Charge per hit in {params.q_unit}\")\n",
    "(charge_df[\"event_q\"] / charge_df[\"event_nhits\"]).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Charge per hit per event in {params.q_unit}\")\n",
    "(charge_df[\"event_q\"] / charge_df[\"event_nhits\"]).to_frame().reset_index().plot.scatter(x=\"eventID\", y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Event charge in {params.q_unit}\")\n",
    "charge_df[\"event_q\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hits q in {params.q_unit}\")\n",
    "charge_df[\"event_hits_q\"].apply(tuple).explode().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hits z in {params.z_unit}\")\n",
    "charge_df[\"event_hits_z\"].apply(tuple).explode().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_df[params.light_variable].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake data map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fake_data([1], buffer=(params.xy_epsilon - 1))\n",
    "if params.show_figures:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=Warning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "if params.event_list is None:\n",
    "    index_list = charge_df.index\n",
    "else:\n",
    "    index_list = charge_df.index.intersection(params.event_list)\n",
    "\n",
    "light_indices = light_df[\"event\"].copy()\n",
    "\n",
    "for i, idx in enumerate(tqdm(index_list)):\n",
    "    charge_values = pd.DataFrame(\n",
    "        charge_df.loc[\n",
    "            idx,\n",
    "            [\n",
    "                \"event_hits_channelid\",\n",
    "                \"event_hits_x\",\n",
    "                \"event_hits_y\",\n",
    "                \"event_hits_z\",\n",
    "                \"event_hits_ts\",\n",
    "                \"event_hits_q\",\n",
    "            ],\n",
    "        ].to_list(),\n",
    "        index=[\"ch\", \"x\", \"y\", \"z\", \"t\", \"q\"],\n",
    "    ).T\n",
    "\n",
    "    non_zero_mask = (charge_values[\"ch\"] != 0) * (charge_values[\"y\"] != 0)  # Remove (0,0) entries\n",
    "    noisy_channels_mask = ~charge_values[\"ch\"].isin([ch[0] for ch in params.channel_disable_list])  # Disable channel 7\n",
    "    mask = non_zero_mask * noisy_channels_mask  # Full hits mask\n",
    "\n",
    "    # Apply boolean indexing to x, y, and z arrays\n",
    "    charge_values = charge_values[mask]\n",
    "    charge_values[\"q\"] = charge_values[\"q\"] * params.charge_gain  # Convert mV to ke\n",
    "\n",
    "    # temp = index_list[i + 1] if i + 1 < len(index_list) else index_list[0]\n",
    "    # light_event = match_dict.get(temp, [temp])[0]\n",
    "    light_event = match_dict.get(idx, [idx])[0]\n",
    "    light_matches = light_indices[light_indices == light_event].index\n",
    "    # light_indices = light_indices[light_indices != light_event]\n",
    "    light_values = light_df.loc[light_matches].dropna(subset=params.light_variable)\n",
    "\n",
    "    if len(charge_values) > 2:\n",
    "        if idx in params.individual_plots:\n",
    "            metrics[idx] = event_display(\n",
    "                idx,\n",
    "                charge_values,\n",
    "                light_values,\n",
    "                plot_cyl=False,\n",
    "            )\n",
    "            if params.show_figures:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "        else:\n",
    "            # Create a design matrix\n",
    "            labels = cluster_hits(charge_values[[\"x\", \"y\", \"z\"]].to_numpy())\n",
    "            # Fit clusters\n",
    "            metrics[idx] = fit_hit_clusters(\n",
    "                charge_values[[\"x\", \"y\", \"z\"]].to_numpy(),\n",
    "                charge_values[\"q\"].to_numpy(),\n",
    "                labels,\n",
    "            )\n",
    "\n",
    "        # Light to track geometry metrics\n",
    "        track_lines = []\n",
    "        for track_idx, values in metrics[idx].items():\n",
    "            if isinstance(track_idx, str) or track_idx <= 0:\n",
    "                continue\n",
    "            values[\"SiPM\"] = light_geometry(\n",
    "                track_line=values[\"Fit_line\"],\n",
    "                track_norm=values[\"Fit_norm\"],\n",
    "                sipm_df=light_values,\n",
    "                light_variable=params.light_variable,\n",
    "            )\n",
    "            track_lines.append(values[\"Fit_line\"])\n",
    "\n",
    "        # Light and charge voxelization and fitting\n",
    "        metrics[idx][\"SiPM\"] = voxelize_hits(\n",
    "            charge_values,\n",
    "            light_values,\n",
    "            params.light_variable,\n",
    "            charge_lines=track_lines,\n",
    "        )\n",
    "\n",
    "        metrics[idx][\"Pixel_mask\"] = mask.to_numpy()  # Save masks to original dataframe for reference\n",
    "        metrics[idx][\"Total_light\"] = light_values[params.light_variable].sum()\n",
    "        metrics[idx][\"Total_charge\"] = charge_values[\"q\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the warning filter (optional)\n",
    "warnings.filterwarnings(\"default\", category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics to a pickle file\n",
    "metrics_file = f\"{params.output_folder}/metrics_{params.output_folder}.pkl\"\n",
    "if params.overwrite_metrics or not os.path.isfile(metrics_file):\n",
    "    with open(metrics_file, \"wb\") as f:\n",
    "        pickle.dump(metrics, f)\n",
    "\n",
    "    print(f\"Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
