{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import uproot\n",
    "from itables import init_notebook_mode\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm, to_rgba\n",
    "from matplotlib.ticker import AutoMinorLocator, MaxNLocator, ScalarFormatter\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from scipy.optimize import curve_fit\n",
    "from skimage.measure import LineModelND, ransac\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from skspatial.objects import Cylinder, Line, Plane, Point, Triangle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "README \n",
    "\n",
    "- `non_track_keys = 5` has to be updated if new keys are added to an event in metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "path_prefix = \"../../data/SoLAr_v2/\"\n",
    "charge_bucket = \"cosmics/root/\"\n",
    "light_bucket = \"root/46v_12db_th950_deco/\"\n",
    "\n",
    "input = \"deco_v3_0cd913fa_20230706_191437.data.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_label = \"_\".join(input.split(\"_\")[-2:]).split(\".\")[0]\n",
    "charge_timestamp = pd.to_datetime(file_label, format=\"%Y%m%d_%H%M%S\").strftime(\n",
    "    \"%Y_%m_%d_%H_%M\"\n",
    ")\n",
    "\n",
    "light_file = path_prefix + \"Light/\" + light_bucket + input\n",
    "charge_file = (\n",
    "    path_prefix\n",
    "    + \"Charge/\"\n",
    "    + charge_bucket\n",
    "    + f\"evd_self_trigger-packets-{charge_timestamp}_CEST_validated.root\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "sipm_map_file = \"sipm_sn_ch_to_xy.json\"\n",
    "\n",
    "# Load options\n",
    "reload_files = True\n",
    "rematch_events = False\n",
    "\n",
    "# Save options\n",
    "overwrite_metrics = True\n",
    "save_figures = True\n",
    "\n",
    "# Plotting options\n",
    "flip_x = True\n",
    "individual_plots = np.arange(1, 11, 1)\n",
    "show_figures = False\n",
    "label_font_size = 16\n",
    "tick_font_size = 16\n",
    "title_font_size = 18\n",
    "\n",
    "# Events to process\n",
    "event_list = None\n",
    "\n",
    "# Noisy Pixels\n",
    "channel_disable_list = [(7, (1, 2))]  # (chip, channel)\n",
    "\n",
    "# Light variable to consider\n",
    "light_variable = \"integral\"\n",
    "\n",
    "# Units for plot labels\n",
    "q_unit = \"e\"  # After applying charge_gain\n",
    "xy_unit = \"mm\"\n",
    "z_unit = \"mm\"\n",
    "dh_unit = \"?\" if z_unit != xy_unit else xy_unit\n",
    "time_unit = \"ns\"\n",
    "light_unit = \"p.e.\" if light_variable == \"integral\" else \"p.e./time bin\"\n",
    "\n",
    "# Conversion factors\n",
    "charge_gain = 245  # mV to e\n",
    "detector_z = 300\n",
    "detector_x = 128\n",
    "detector_y = 160\n",
    "sipm_size = 6\n",
    "pixel_size = 3\n",
    "pixel_pitch = 4\n",
    "quadrant_size = 32  # One SiPM + LArPix cell\n",
    "first_chip = (2, 1) if detector_y == 160 else (1, 1)\n",
    "\n",
    "# DBSCAN parameters for charge clustering\n",
    "min_samples = 2\n",
    "xy_epsilon = 8  # 8 ideal\n",
    "z_epsilon = 8  # 8 ideal\n",
    "\n",
    "# RANSAC parameters for line fitting\n",
    "ransac_residual_threshold = 6  # 6 ideal for charge, 35 ideal for light\n",
    "ransac_max_trials = 1000\n",
    "ransac_min_samples = 2  # 2 ideal for charge, 3 ideal for light\n",
    "\n",
    "# Force parameters for cylinder\n",
    "force_dh = None\n",
    "force_dr = None\n",
    "\n",
    "# Filters for post processing\n",
    "score_cutoff = -1.0\n",
    "max_score = 1.0\n",
    "min_track_length = 30\n",
    "max_track_length = np.inf\n",
    "max_tracks = 1\n",
    "\n",
    "# Other\n",
    "non_track_keys = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SiPMs mapping\n",
    "sipm_map = None\n",
    "\n",
    "\n",
    "def sipm_to_xy(sn, ch):\n",
    "    global sipm_map\n",
    "    if sipm_map is None:\n",
    "        with open(sipm_map_file, \"r\") as f:\n",
    "            sipm_map = json.load(f)\n",
    "\n",
    "    xy = sipm_map.get(str(sn), {}).get(str(ch), None)\n",
    "    if xy is None:\n",
    "        return None\n",
    "    else:\n",
    "        x = xy[0] + 64\n",
    "        y = xy[1] - 16\n",
    "        return (x, y)\n",
    "\n",
    "\n",
    "# Check if SiPMs on anode area\n",
    "def get_sipm_mask(sn, ch):\n",
    "    xy = sipm_to_xy(sn, ch)\n",
    "    # return True\n",
    "    if xy is None:\n",
    "        return False\n",
    "    else:\n",
    "        return (\n",
    "            xy[0] > -detector_x / 2\n",
    "            and xy[0] < detector_x / 2\n",
    "            and xy[1] < detector_y / 2\n",
    "            and xy[1] > -detector_y / 2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cylinder parameters for dQ/dx\n",
    "def get_dh(unit_vector):\n",
    "    if force_dh is not None:\n",
    "        return force_dh\n",
    "\n",
    "    dl_vector = np.array([xy_epsilon, xy_epsilon, z_epsilon])\n",
    "    min_dh = np.linalg.norm(dl_vector) / 4\n",
    "    max_dh = 2 * np.linalg.norm(dl_vector)\n",
    "    dl_projection = abs(np.dot(unit_vector, dl_vector))\n",
    "    dh = min(max(dl_projection, min_dh), max_dh)\n",
    "\n",
    "    return dh\n",
    "\n",
    "\n",
    "def get_dr(rmse):\n",
    "    if force_dr is not None:\n",
    "        return force_dr\n",
    "\n",
    "    dl_vector = np.array([xy_epsilon, xy_epsilon, z_epsilon])\n",
    "    min_dr = np.linalg.norm(dl_vector) / 4\n",
    "    dr = max(rmse, min_dr)\n",
    "\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dict = {}\n",
    "\n",
    "\n",
    "def match_events(charge_df, light_df, window=10):\n",
    "    match_dict = {}\n",
    "\n",
    "    charge_events = charge_df[[\"event_unix_ts\", \"event_start_t\"]].drop_duplicates()\n",
    "    light_events = light_df[[\"tai_ns\", \"event\"]].drop_duplicates()\n",
    "\n",
    "    for event, row in tqdm(charge_events.iterrows(), total=len(charge_events)):\n",
    "        charge_ts = (float(row[\"event_unix_ts\"]) * 1e6) + (\n",
    "            float(row[\"event_start_t\"]) * 1e-1\n",
    "        )\n",
    "        light_matches = light_events.where(\n",
    "            abs(light_events[\"tai_ns\"].astype(float) * 1e-3 - 36000000 - charge_ts)\n",
    "            <= window\n",
    "        ).dropna()\n",
    "\n",
    "        if not light_matches.empty:\n",
    "            if event in match_dict:\n",
    "                match_dict[event].append(\n",
    "                    light_matches[\"event\"].unique().astype(int).tolist()\n",
    "                )\n",
    "            else:\n",
    "                match_dict[event] = light_matches[\"event\"].unique().astype(int).tolist()\n",
    "\n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of fake data\n",
    "def generate_dead_area(z_range, buffer=1):\n",
    "    # Dead area on SiPMs\n",
    "    fake_x = []\n",
    "    fake_y = []\n",
    "    fake_z = []\n",
    "\n",
    "    border = buffer - pixel_pitch / 2\n",
    "\n",
    "    for k in range((detector_x // quadrant_size)):\n",
    "        for l in range((detector_y // quadrant_size)):\n",
    "            # Dead area on chips 33, 44, 54, 64\n",
    "            if (l + first_chip[0], k + first_chip[1]) in [\n",
    "                (3, 3),\n",
    "                (4, 4),\n",
    "                (5, 4),\n",
    "                (6, 4),\n",
    "            ]:\n",
    "                # continue\n",
    "                temp_x, temp_y, temp_z = np.meshgrid(\n",
    "                    np.linspace(\n",
    "                        border, quadrant_size - border, int(quadrant_size / buffer)\n",
    "                    )\n",
    "                    - detector_x / 2\n",
    "                    + quadrant_size * (k),\n",
    "                    -np.linspace(\n",
    "                        border, quadrant_size - border, int(quadrant_size / buffer)\n",
    "                    )\n",
    "                    + detector_y / 2\n",
    "                    - quadrant_size * (l),\n",
    "                    z_range,\n",
    "                )\n",
    "\n",
    "                fake_x.extend(temp_x.flatten())\n",
    "                fake_y.extend(temp_y.flatten())\n",
    "                fake_z.extend(temp_z.flatten())\n",
    "            # Dead area on chip 42\n",
    "            elif k + first_chip[1] == 2 and l + first_chip[0] == 4:\n",
    "                temp_x, temp_y, temp_z = np.meshgrid(\n",
    "                    np.linspace(\n",
    "                        border, quadrant_size - border, int(quadrant_size / buffer)\n",
    "                    ),\n",
    "                    np.linspace(\n",
    "                        border, quadrant_size - border, int(quadrant_size / buffer)\n",
    "                    ),\n",
    "                    z_range,\n",
    "                )\n",
    "\n",
    "                mask1 = (temp_y - quadrant_size / 2) - (temp_x - quadrant_size / 2) >= 0\n",
    "                mask2 = (temp_y <= quadrant_size / 2 + buffer) & (\n",
    "                    temp_y >= quadrant_size / 2 - buffer\n",
    "                )\n",
    "                mask3 = (temp_x <= quadrant_size / 2 + buffer) & (\n",
    "                    temp_x >= quadrant_size / 2 - buffer\n",
    "                )\n",
    "                mask = mask1 | (mask2 & mask3)\n",
    "                temp_x = temp_x[mask] - detector_x / 2 + quadrant_size * (k)\n",
    "                temp_y = -temp_y[mask] + detector_y / 2 - quadrant_size * (l)\n",
    "                temp_z = temp_z[mask]\n",
    "\n",
    "                fake_x.extend(temp_x)\n",
    "                fake_y.extend(temp_y)\n",
    "                fake_z.extend(temp_z)\n",
    "            # Dead area on SiPMs\n",
    "            else:\n",
    "                sipm_points = int((sipm_size + pixel_pitch) / (buffer))\n",
    "                if sipm_points > 1:\n",
    "                    x1 = np.linspace(\n",
    "                        -(sipm_size + pixel_pitch) / 2 + buffer,\n",
    "                        +(sipm_size + pixel_pitch) / 2 - buffer,\n",
    "                        sipm_points,\n",
    "                    )\n",
    "                else:\n",
    "                    x1 = np.array([0])\n",
    "\n",
    "                x1 = quadrant_size / 2 + x1\n",
    "\n",
    "                temp_x, temp_y, temp_z = np.meshgrid(\n",
    "                    x1 - detector_x / 2 + quadrant_size * k,\n",
    "                    -x1 + detector_y / 2 - quadrant_size * l,\n",
    "                    z_range,\n",
    "                )\n",
    "\n",
    "                # Removing channel 7\n",
    "                disable_x, disable_y, disable_z = [], [], []\n",
    "\n",
    "                for channel in channel_disable_list:\n",
    "                    coords = channel[1]\n",
    "                    temp_x2, temp_y2, temp_z2 = np.meshgrid(\n",
    "                        np.array(\n",
    "                            [\n",
    "                                -detector_x / 2\n",
    "                                + (coords[0] * pixel_pitch)\n",
    "                                + (pixel_pitch - pixel_size)\n",
    "                            ]\n",
    "                        )\n",
    "                        + quadrant_size * k,\n",
    "                        np.array(\n",
    "                            [\n",
    "                                detector_y / 2\n",
    "                                - (coords[1] * pixel_pitch)\n",
    "                                - (pixel_pitch - pixel_size)\n",
    "                            ]\n",
    "                        )\n",
    "                        - quadrant_size * l,\n",
    "                        z_range,\n",
    "                    )\n",
    "                    disable_x.extend(temp_x2)\n",
    "                    disable_y.extend(temp_y2)\n",
    "                    disable_z.extend(temp_z2)\n",
    "\n",
    "                fake_x.extend(np.append(temp_x, disable_x))\n",
    "                fake_y.extend(np.append(temp_y, disable_y))\n",
    "                fake_z.extend(np.append(temp_z, disable_z))\n",
    "\n",
    "    fake_x = np.array(fake_x)\n",
    "    fake_y = np.array(fake_y)\n",
    "    fake_z = np.array(fake_z)\n",
    "\n",
    "    fake_data = np.c_[np.power(-1, flip_x) * fake_x, fake_y, fake_z]\n",
    "\n",
    "    return fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN clustering\n",
    "def cluster_hits(hitArray):\n",
    "    # First stage clustering\n",
    "    z_intervals = []\n",
    "    first_stage = DBSCAN(eps=xy_epsilon, min_samples=min_samples).fit(hitArray[:, 0:2])\n",
    "    for label in first_stage.labels_:\n",
    "        if label > -1:\n",
    "            mask = first_stage.labels_ == label\n",
    "            z = hitArray[mask, 2]\n",
    "            z_intervals.append((min(z), max(z)))\n",
    "\n",
    "    # Sort the intervals based on their start points\n",
    "    sorted_intervals = sorted(z_intervals, key=lambda interval: interval[0])\n",
    "\n",
    "    # Initialize a list to store the intervals representing the empty space\n",
    "    empty_space_ranges = []\n",
    "\n",
    "    # Iterate through the sorted intervals to find the gaps\n",
    "    for i in range(len(sorted_intervals) - 1):\n",
    "        current_interval = sorted_intervals[i]\n",
    "        next_interval = sorted_intervals[i + 1]\n",
    "\n",
    "        # Calculate the gap between the current interval and the next interval\n",
    "        gap_start = current_interval[1]\n",
    "        gap_end = next_interval[0]\n",
    "\n",
    "        # Check if there is a gap (empty space) between intervals\n",
    "        if gap_end > gap_start and gap_end < gap_start + 40:\n",
    "            empty_space_ranges.append(np.arange(gap_start, gap_end, z_epsilon))\n",
    "\n",
    "    if not empty_space_ranges:\n",
    "        if np.std(hitArray[:, 2]) > 0:\n",
    "            z_range = np.arange(\n",
    "                np.mean(hitArray[:, 2]) - np.std(hitArray[:, 2]),\n",
    "                np.mean(hitArray[:, 2]) + np.std(hitArray[:, 2]),\n",
    "                z_epsilon,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            z_range = [np.mean(hitArray[:, 2])]\n",
    "\n",
    "    else:\n",
    "        z_range = np.concatenate(empty_space_ranges)\n",
    "\n",
    "    # Create a list of holes\n",
    "    fake_data = generate_dead_area(z_range, buffer=(xy_epsilon - 1))\n",
    "    fake_data_count = len(fake_data)\n",
    "\n",
    "    # Second stage clustering\n",
    "    # Combine fake to true data\n",
    "    second_stage_data = np.concatenate([hitArray, fake_data])\n",
    "    second_stage = DBSCAN(eps=xy_epsilon, min_samples=1).fit(second_stage_data[:, 0:2])\n",
    "\n",
    "    # Third stage clustering\n",
    "    # Create a new array with z and labels\n",
    "    third_stage_z = np.c_[second_stage.labels_ * 1e3, second_stage_data[:, 2]]\n",
    "    labels = second_stage.labels_.copy()\n",
    "    flag = labels > -1\n",
    "\n",
    "    third_stage_data = third_stage_z[flag].copy()\n",
    "    third_stage = DBSCAN(\n",
    "        eps=z_epsilon, min_samples=min_samples, metric=\"chebyshev\"\n",
    "    ).fit(third_stage_data)\n",
    "\n",
    "    # Shift labels by 1 so that negative values are reserved for outliers\n",
    "    labels[flag] = third_stage.labels_ + 1\n",
    "\n",
    "    # Remove fake data\n",
    "    if fake_data_count > 0:\n",
    "        labels = labels[:-fake_data_count]\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "# Apply Ransac Fit\n",
    "def ransacFit(\n",
    "    hitArray,\n",
    "    weightArray=None,\n",
    "    min_samples=None,\n",
    "    residual_threshold=None,\n",
    "):\n",
    "    if weightArray is not None:\n",
    "        estimator = RANSACRegressor(\n",
    "            min_samples=min_samples,\n",
    "            max_trials=ransac_max_trials,\n",
    "            residual_threshold=residual_threshold,\n",
    "        )\n",
    "        last_column = len(hitArray[0]) - 1\n",
    "        inliers = estimator.fit(\n",
    "            hitArray[:, 0:last_column],\n",
    "            hitArray[:, last_column],\n",
    "            sample_weight=weightArray,\n",
    "        ).inlier_mask_\n",
    "\n",
    "        # Check it enouth inliers\n",
    "        if sum(inliers) > ransac_min_samples:\n",
    "            score = estimator.score(\n",
    "                hitArray[:, 0:last_column], hitArray[:, last_column]\n",
    "            )\n",
    "        else:\n",
    "            score = np.nan\n",
    "    else:\n",
    "        model_robust, inliers = ransac(\n",
    "            hitArray,\n",
    "            LineModelND,\n",
    "            min_samples=min_samples,\n",
    "            residual_threshold=residual_threshold,\n",
    "            max_trials=ransac_max_trials,\n",
    "        )\n",
    "\n",
    "        # Check it enouth inliers\n",
    "        if sum(inliers) > ransac_min_samples:\n",
    "            score = model_robust.residuals(hitArray)\n",
    "        else:\n",
    "            score = np.nan\n",
    "\n",
    "    outliers = inliers == False\n",
    "    return inliers, outliers, score\n",
    "\n",
    "\n",
    "# Apply best line fit\n",
    "def lineFit(hitArray):\n",
    "    line = Line.best_fit(hitArray)\n",
    "    max_point = Point(np.max(hitArray, axis=0))\n",
    "    min_point = Point(np.min(hitArray, axis=0))\n",
    "    centre_point = (max_point + min_point) / 2\n",
    "    line.point = line.project_point(centre_point)\n",
    "    residuals = np.array([line.distance_point(point) for point in hitArray])\n",
    "\n",
    "    # Calculate chi-squared\n",
    "    mse = np.sum(residuals**2) / len(residuals)\n",
    "\n",
    "    return line, mse\n",
    "\n",
    "\n",
    "# Calculate dQ/dx from a line fit\n",
    "def dqdx(hitArray, q, line_fit, dh, dr, h, ax=None):\n",
    "    # Cylinder steps for dQ/dx\n",
    "    steps = np.arange(-3 * dh, h + 3 * dh, dh)\n",
    "\n",
    "    # Mask of points that have been accounted for\n",
    "    counted = np.zeros(len(q), dtype=bool)\n",
    "\n",
    "    # Array of dQ values for each step\n",
    "    dq_i = np.zeros(len(steps), dtype=float)\n",
    "\n",
    "    for step_idx, step in enumerate(steps):\n",
    "        cylinder_fit = Cylinder(\n",
    "            line_fit.to_point(step - h / 2),\n",
    "            line_fit.direction.unit() * dh,\n",
    "            dr,\n",
    "        )\n",
    "        if ax is not None:\n",
    "            cylinder_fit.plot_3d(ax)\n",
    "\n",
    "        for point_idx, point in enumerate(hitArray):\n",
    "            if not counted[point_idx] and cylinder_fit.is_point_within(point):\n",
    "                counted[point_idx] = True\n",
    "                dq_i[step_idx] += q[point_idx]\n",
    "\n",
    "    return dq_i\n",
    "\n",
    "\n",
    "# Fit clusters with Ransac method\n",
    "def fit_hit_clusters(\n",
    "    hitArray,\n",
    "    q,\n",
    "    labels,\n",
    "    ax2d=None,\n",
    "    ax3d=None,\n",
    "    plot_cyl=False,\n",
    "    refit_outliers=True,\n",
    "):\n",
    "    metrics = {}\n",
    "    # Fit clusters\n",
    "    idx = 0\n",
    "    condition = lambda: idx < len(np.unique(labels))\n",
    "    while condition():\n",
    "        label = np.unique(labels)[idx]\n",
    "        mask = labels == label\n",
    "        if label > 0 and mask.sum() > min_samples:\n",
    "            xyz_c = hitArray[mask]\n",
    "            q_c = np.array(q)[mask]\n",
    "\n",
    "            norm = np.linalg.norm(np.max(xyz_c, axis=0) - np.min(xyz_c, axis=0))\n",
    "\n",
    "            # Fit the model\n",
    "            inliers, outliers, score = ransacFit(\n",
    "                xyz_c,\n",
    "                weightArray=q_c - min(q_c) + 1,\n",
    "                min_samples=ransac_min_samples,\n",
    "                residual_threshold=ransac_residual_threshold,\n",
    "            )\n",
    "\n",
    "            # Refit outliers\n",
    "            level_1 = np.where(mask)[0]\n",
    "            level_2 = np.where(outliers)[0]\n",
    "            level_3 = level_1[level_2]\n",
    "\n",
    "            if refit_outliers and sum(outliers) > min_samples:\n",
    "                outlier_labels = cluster_hits(xyz_c[outliers])\n",
    "                last_label = max(labels) + 1\n",
    "                # Assign positive labels to clustered outliers and negative labels to unlclustered outliers\n",
    "                for i, j in enumerate(level_3):\n",
    "                    labels[j] = (outlier_labels[i] + last_label) * (\n",
    "                        1 if outlier_labels[i] > 0 else -1\n",
    "                    )\n",
    "            else:\n",
    "                # Assign negative labels to outliers\n",
    "                for j in level_3:\n",
    "                    labels[j] = -labels[j]\n",
    "\n",
    "            if sum(inliers) > min_samples:\n",
    "                line_fit, mse = lineFit(xyz_c[inliers])\n",
    "\n",
    "                if ax2d is not None:\n",
    "                    # 2D plot\n",
    "                    line_fit.plot_2d(\n",
    "                        ax2d,\n",
    "                        t_1=-norm / 2,\n",
    "                        t_2=norm / 2,\n",
    "                        c=\"red\",\n",
    "                        label=f\"Track {label}\",\n",
    "                        zorder=10,\n",
    "                    )\n",
    "                if ax3d is not None:\n",
    "                    # 3D plot\n",
    "                    line_fit.plot_3d(\n",
    "                        ax3d,\n",
    "                        t_1=-norm / 2,\n",
    "                        t_2=norm / 2,\n",
    "                        c=\"red\",\n",
    "                        label=f\"Track {label}\",\n",
    "                    )\n",
    "\n",
    "                # Calculate dQ/dx\n",
    "                dh = get_dh(line_fit.direction)\n",
    "                dr = get_dr(np.sqrt(mse))\n",
    "\n",
    "                dq_i = dqdx(\n",
    "                    xyz_c[inliers],\n",
    "                    q_c[inliers],\n",
    "                    line_fit,\n",
    "                    dh=dh,\n",
    "                    dr=dr,\n",
    "                    h=norm,\n",
    "                    ax=ax3d if ax3d is not None and plot_cyl else None,\n",
    "                )\n",
    "\n",
    "                q_eff = dq_i.sum() / q_c[inliers].sum()\n",
    "                if dq_i.sum() != 0:\n",
    "                    dq = dq_i\n",
    "                else:\n",
    "                    dq = 0\n",
    "\n",
    "                metrics[label] = {\n",
    "                    \"Fit_line\": line_fit,\n",
    "                    \"Fit_norm\": norm,\n",
    "                    \"Fit_mse\": mse,\n",
    "                    \"RANSAC_score\": score,\n",
    "                    \"q_eff\": q_eff,\n",
    "                    \"dQ\": dq,\n",
    "                    \"dx\": dh,\n",
    "                }\n",
    "\n",
    "        idx = np.unique(labels).tolist().index(label) + 1\n",
    "\n",
    "    metrics[\"Fit_labels\"] = labels\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize_hits(\n",
    "    charge_df,\n",
    "    sipm_df,\n",
    "    light_variable,\n",
    "    fit_light=True,\n",
    "    charge_lines=[],\n",
    "):\n",
    "    sipm_voxels_metrics = {}\n",
    "    xyzl_df = pd.DataFrame()\n",
    "    for row, sipm in sipm_df.dropna(subset=light_variable).iterrows():\n",
    "        voxel_mask = (abs(charge_df[\"x\"] - sipm[\"x\"]) <= quadrant_size / 2) & (\n",
    "            abs(charge_df[\"y\"] - sipm[\"y\"]) <= quadrant_size / 2\n",
    "        )\n",
    "        voxel_charge = charge_df[\"q\"][voxel_mask]\n",
    "        voxel_z = charge_df[\"z\"][voxel_mask]\n",
    "        xyzl = sipm[[\"x\", \"y\", light_variable]].copy()\n",
    "\n",
    "        if len(voxel_charge) > 0:\n",
    "            sipm_idx = (sipm[\"sn\"], sipm[\"ch\"])\n",
    "            sipm_voxels_metrics[sipm_idx] = {}\n",
    "            voxel_mean_z = np.average(voxel_z, weights=voxel_charge)\n",
    "            voxel_total_charge = voxel_charge.sum()\n",
    "            sipm_voxels_metrics[sipm_idx][\"charge_q\"] = voxel_total_charge\n",
    "            sipm_voxels_metrics[sipm_idx][\"charge_z\"] = voxel_mean_z\n",
    "            sipm_voxels_metrics[sipm_idx][light_variable] = sipm[light_variable]\n",
    "            xyzl[\"z\"] = voxel_mean_z\n",
    "        else:\n",
    "            xyzl[\"z\"] = np.average(charge_df[\"z\"], weights=charge_df[\"q\"])\n",
    "\n",
    "            if charge_lines:\n",
    "                point = Point([sipm[\"x\"], sipm[\"y\"], 0])\n",
    "                plane = Plane(point=point, normal=[0, 0, 1])\n",
    "                line_distances = [\n",
    "                    (\n",
    "                        line.distance_point(point)\n",
    "                        if not plane.normal.is_parallel(line.direction)\n",
    "                        else np.inf\n",
    "                    )\n",
    "                    for line in charge_lines\n",
    "                ]\n",
    "                if line_distances and min(line_distances) < np.inf:\n",
    "                    charge_line = charge_lines[np.argmin(line_distances)]\n",
    "                    projection = plane.project_line(charge_line)\n",
    "                    projected_point = projection.project_point(point)\n",
    "                    v_line = Line(point=projected_point, direction=[0, 0, 1])\n",
    "                    intersection = charge_line.intersect_line(\n",
    "                        v_line, check_coplanar=False\n",
    "                    )\n",
    "                    if all(abs(projected_point - point)[:2] <= quadrant_size / 2):\n",
    "                        xyzl[\"z\"] = intersection[2]\n",
    "\n",
    "        xyzl_df = pd.concat([xyzl_df, xyzl], axis=1)\n",
    "\n",
    "    if not xyzl_df.empty and fit_light:\n",
    "        xyzl_df = xyzl_df.T\n",
    "        xyzl_df = xyzl_df.sort_values(by=light_variable, ascending=False)\n",
    "        xyzl_df = xyzl_df[xyzl_df[light_variable] > 0]\n",
    "        if len(xyzl_df) > 3:\n",
    "            # dbscan = DBSCAN(eps=quadrant_size, metric=\"chebyshev\", min_samples=2)\n",
    "            # labels = dbscan.fit(xyzl_df[[\"x\", \"y\"]].values).labels_\n",
    "            # unique, counts = np.unique(labels[labels>-1],return_counts=True)\n",
    "            # if len(counts)>0 and max(counts)>3:\n",
    "            #     label = unique[counts.argmax()]\n",
    "\n",
    "            #     xyz = xyzl_df[labels==label].head(5)\n",
    "            xyzl = xyzl_df.head(5).astype(float)\n",
    "            inliers, outliers, score = ransacFit(\n",
    "                xyzl[[\"x\", \"y\", \"z\"]].values,\n",
    "                weightArray=xyzl[light_variable].values,\n",
    "                min_samples=3,\n",
    "                residual_threshold=10,\n",
    "            )\n",
    "            if inliers.sum() > 2:\n",
    "                light_fit, mse = lineFit(xyzl[[\"x\", \"y\", \"z\"]][inliers].values)\n",
    "                sipm_voxels_metrics[\"Fit_line\"] = light_fit\n",
    "                sipm_voxels_metrics[\"RANSAC_score\"] = score\n",
    "                sipm_voxels_metrics[\"Fit_mse\"] = mse\n",
    "                sipm_voxels_metrics[\"Fit_threshold\"] = xyzl[light_variable][\n",
    "                    inliers\n",
    "                ].min()\n",
    "\n",
    "    return sipm_voxels_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_geometry(track_line, track_norm, sipm_df, light_variable=\"integral\"):\n",
    "    metrics = {}\n",
    "    point1 = track_line.to_point(-track_norm / 2)\n",
    "    point2 = track_line.to_point(track_norm / 2)\n",
    "    centre = track_line.point\n",
    "\n",
    "    iterate_df = sipm_df.dropna(subset=light_variable).copy()\n",
    "    for row, sipm in iterate_df.iterrows():\n",
    "        sipm_idx = (sipm[\"sn\"], sipm[\"ch\"])\n",
    "        point3 = Point([sipm[\"x\"], sipm[\"y\"], 0])\n",
    "        triangle = Triangle(point1, point2, point3)\n",
    "        angle = triangle.angle(\"C\")\n",
    "        distance = point3.distance_point(centre)\n",
    "        metrics[sipm_idx] = {}\n",
    "        metrics[sipm_idx][\"distance\"] = distance\n",
    "        metrics[sipm_idx][\"angle\"] = angle\n",
    "        metrics[sipm_idx][light_variable] = sipm[light_variable]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_std(array, ax=None, array_max=None, min_count_ratio=0.9, max_std_ratio=0.5):\n",
    "    max_std = array.std()\n",
    "    max_count = len(array)\n",
    "    if array_max is None:\n",
    "        array_max = np.percentile(array, min(min_count_ratio * 100 + 1, 100))\n",
    "\n",
    "    std = []\n",
    "    count = []\n",
    "    x_range = range(int(min(array)), (int(array_max) + 1), 1)\n",
    "    for i in x_range:\n",
    "        cut = array[array < i]\n",
    "        std.append(cut.std())\n",
    "        count.append(len(cut))\n",
    "\n",
    "    std = np.array(std)\n",
    "    count = np.array(count)\n",
    "    condition = ((count / max_count).round(3) >= min_count_ratio) & (\n",
    "        (std / max_std).round(3) <= max_std_ratio\n",
    "    )\n",
    "    vline = x_range[\n",
    "        (\n",
    "            np.where(condition)[0][-1]\n",
    "            if np.any(condition)\n",
    "            else (count / max_count > min_count_ratio).argmax()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        \"Max STD ratio\",\n",
    "        max_std_ratio,\n",
    "        \"limited to\",\n",
    "        min_count_ratio * 100,\n",
    "        \"% of events:\",\n",
    "        vline,\n",
    "        \"\\n\",\n",
    "    )\n",
    "    if ax is not None:\n",
    "        ax.plot(std / max_std, label=\"STD ratio\")\n",
    "        ax.plot(count / max_count, label=\"Event count ratio\")\n",
    "        ax.axvline(vline, ls=\"--\", c=\"r\", label=f\"{min_count_ratio*100}% of events\")\n",
    "        ax.legend()\n",
    "        ax.tick_params(\n",
    "            axis=\"both\", direction=\"inout\", which=\"major\", top=True, right=True\n",
    "        )\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.grid(alpha=0.25)\n",
    "\n",
    "    return vline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hot_bins(min_n_ratio, n, x_edges, y_edges, scale=(1, 1), eps=8):\n",
    "    n[np.isnan(n)] = 0\n",
    "    min_n = min_n_ratio * n.max()\n",
    "    filtered_n2 = n[n >= min_n]\n",
    "    bin_centers_x = 0.5 * (x_edges[1:] + x_edges[:-1])\n",
    "    bin_centers_y = 0.5 * (y_edges[1:] + y_edges[:-1])\n",
    "    filtered_centers_x, filtered_centers_y = np.array(\n",
    "        np.meshgrid(bin_centers_x, bin_centers_y)\n",
    "    )\n",
    "    filtered_centers_x = filtered_centers_x[n.T > min_n]\n",
    "    filtered_centers_y = filtered_centers_y[n.T > min_n]\n",
    "    dbscan = DBSCAN(\n",
    "        eps=eps, min_samples=int(np.sqrt(len(filtered_centers_y))), metric=\"chebyshev\"\n",
    "    ).fit(np.c_[filtered_centers_x / scale[0], filtered_centers_y / scale[1]])\n",
    "    return filtered_centers_x, filtered_centers_y, dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak finding algorithm for integration\n",
    "def integrate_peaks(waveform, buffer_size=10, height=0.1, prominence=0.05):\n",
    "    # Find peaks in the filtered waveform\n",
    "    peaks, properties = signal.find_peaks(\n",
    "        waveform, height=height, prominence=prominence\n",
    "    )\n",
    "\n",
    "    integration_result = 0\n",
    "    start_index = 0  # Initialize the start index\n",
    "    end_index = 0  # Initialize the end index\n",
    "\n",
    "    for peak in peaks:\n",
    "        # Determine the potential start and end indices\n",
    "        potential_start = max(0, peak - buffer_size)\n",
    "        potential_end = min(len(waveform), peak + buffer_size)\n",
    "\n",
    "        # If the potential start is within the current peak region, update the end index\n",
    "        if potential_start <= end_index:\n",
    "            end_index = potential_end\n",
    "        else:\n",
    "            # Integrate the previous peak region and update indices for the new peak\n",
    "            peak_region = waveform[start_index:end_index]\n",
    "            integration_result += np.trapz(peak_region)\n",
    "            start_index = potential_start\n",
    "            end_index = potential_end\n",
    "\n",
    "    # Integrate the last peak region\n",
    "    peak_region = waveform[start_index:end_index]\n",
    "    integration_result += np.trapz(peak_region)\n",
    "\n",
    "    return integration_result, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metrics(\n",
    "    metrics,\n",
    "    min_score=0.5,\n",
    "    max_score=np.inf,\n",
    "    min_track_length=160,\n",
    "    max_track_length=np.inf,\n",
    "    max_tracks=1,\n",
    "):\n",
    "    print(f\"min_score = {min_score}\")\n",
    "    print(f\"max_score = {max_score}\")\n",
    "    print(f\"min_track_length = {min_track_length}\")\n",
    "    print(f\"max_track_length = {max_track_length}\")\n",
    "    print(f\"max_tracks = {max_tracks}\")\n",
    "\n",
    "    filtered_metrics = {}\n",
    "\n",
    "    for event_idx, metric in metrics.items():\n",
    "        if len(metric) <= max_tracks + non_track_keys:\n",
    "            candidate_metric = {\n",
    "                track_idx: values\n",
    "                for track_idx, values in metric.items()\n",
    "                if isinstance(track_idx, str)\n",
    "                or (\n",
    "                    track_idx > 0\n",
    "                    and values[\"RANSAC_score\"] >= min_score\n",
    "                    and values[\"RANSAC_score\"] <= max_score\n",
    "                    and values[\"Fit_norm\"] >= min_track_length\n",
    "                    and values[\"Fit_norm\"] <= max_track_length\n",
    "                )\n",
    "            }\n",
    "            if (\n",
    "                len(candidate_metric) <= max_tracks + non_track_keys\n",
    "                and len(candidate_metric) > non_track_keys\n",
    "            ):\n",
    "                filtered_metrics[event_idx] = candidate_metric\n",
    "\n",
    "    print(f\"{len(filtered_metrics)} metrics remaining\")\n",
    "    return filtered_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uproot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uproot\n",
    "def load_charge(file_name, events=None):\n",
    "    with uproot.open(file_name) as f:\n",
    "        charge_df = f[\"events\"].arrays(library=\"pd\").set_index(\"eventID\")\n",
    "        if events is not None:\n",
    "            charge_df = charge_df.loc[events]\n",
    "\n",
    "    return charge_df\n",
    "\n",
    "\n",
    "def load_light(file_name, deco=True, events=None, mask=True, keep_rwf=False):\n",
    "    light_df = pd.DataFrame()\n",
    "    with uproot.open(file_name) as f:\n",
    "        if deco:\n",
    "            tree = f[\"decowave\"]\n",
    "        else:\n",
    "            tree = f[\"rwf_array\"]\n",
    "\n",
    "        scaling_par = 655.340\n",
    "        if \"scaling_par\" in f:\n",
    "            scaling_par = f[\"scaling_par\"].value\n",
    "\n",
    "        for idx, arrays in enumerate(tree.iterate(library=\"np\")):\n",
    "            df = pd.DataFrame.from_dict(arrays, orient=\"index\").T\n",
    "            df.dropna()\n",
    "            if events is not None:\n",
    "                df = df[df[\"event\"].isin(events)]\n",
    "\n",
    "            df[[\"sn\", \"ch\"]] = df[[\"sn\", \"ch\"]].astype(int)\n",
    "\n",
    "            if mask:\n",
    "                df = df[\n",
    "                    df[[\"sn\", \"ch\"]].apply(\n",
    "                        lambda x: get_sipm_mask(x.iloc[0], x.iloc[1]), axis=1\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            df[[\"x\", \"y\"]] = df[[\"sn\", \"ch\"]].apply(\n",
    "                lambda x: pd.Series(sipm_to_xy(x.iloc[0], x.iloc[1])), axis=1\n",
    "            )\n",
    "\n",
    "            if deco:\n",
    "                df[\"rwf\"] = df[\"decwfm\"]\n",
    "\n",
    "            df[\"rwf\"] = df[\"rwf\"].apply(lambda x: x / scaling_par)\n",
    "\n",
    "            df[[\"integral\", \"properties\"]] = df[\"rwf\"].apply(\n",
    "                lambda x: pd.Series(\n",
    "                    (np.nan, {}) if any(np.isnan(x)) else integrate_peaks(x)\n",
    "                )\n",
    "            )\n",
    "            df[\"peak\"] = df[\"properties\"].apply(\n",
    "                lambda x: (\n",
    "                    max(x[\"peak_heights\"])\n",
    "                    if \"peak_heights\" in x and len(x[\"peak_heights\"]) > 0\n",
    "                    else np.nan\n",
    "                )\n",
    "            )\n",
    "\n",
    "            columns = [\"event\", \"tai_ns\", \"sn\", \"ch\", \"peak\", \"integral\", \"x\", \"y\"]\n",
    "            if keep_rwf:\n",
    "                columns.append(\"rwf\")\n",
    "\n",
    "            df = df[columns]\n",
    "            light_df = pd.concat([light_df, df], ignore_index=True)\n",
    "\n",
    "    return light_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OOMFormatter(ScalarFormatter):\n",
    "    def __init__(self, order=0, fformat=\"%1.1f\", offset=True, mathText=True):\n",
    "        self.oom = order\n",
    "        self.fformat = fformat\n",
    "        ScalarFormatter.__init__(self, useOffset=offset, useMathText=mathText)\n",
    "\n",
    "    def _set_order_of_magnitude(self):\n",
    "        self.orderOfMagnitude = self.oom\n",
    "\n",
    "    def _set_format(self, vmin=None, vmax=None):\n",
    "        self.format = self.fformat\n",
    "        if self._useMathText:\n",
    "            self.format = r\"$\\mathdefault{%s}$\" % self.format\n",
    "\n",
    "\n",
    "def set_common_ax_options(ax=None, cbar=None):\n",
    "    if ax is not None:\n",
    "        ax.tick_params(\n",
    "            axis=\"both\",\n",
    "            direction=\"inout\",\n",
    "            which=\"major\",\n",
    "            top=True,\n",
    "            right=True,\n",
    "            labelsize=tick_font_size,\n",
    "        )\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid(alpha=0.25)\n",
    "        ax.set_title(ax.get_title(), fontsize=title_font_size)\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontsize=label_font_size)\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=label_font_size)\n",
    "        if hasattr(ax, \"get_zlabel\"):\n",
    "            ax.set_zlabel(ax.get_zlabel(), fontsize=label_font_size)\n",
    "\n",
    "        if not ax.get_xscale() == \"log\":\n",
    "            ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "            if ax.get_xlim()[1] > 1.1:\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=(ax.get_xlim()[1] > 2)))\n",
    "                if ax.get_xlim()[1] > 1e3:\n",
    "                    ax.xaxis.set_major_formatter(OOMFormatter(3, \"%1.1f\"))\n",
    "\n",
    "        if not ax.get_yscale() == \"log\":\n",
    "            ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "            if ax.get_ylim()[1] > 1.1:\n",
    "                ax.yaxis.set_major_locator(MaxNLocator(integer=(ax.get_ylim()[1] > 2)))\n",
    "                if ax.get_ylim()[1] > 1e3:\n",
    "                    ax.yaxis.set_major_formatter(OOMFormatter(3, \"%1.1f\"))\n",
    "\n",
    "    if cbar is not None:\n",
    "        cbar.ax.tick_params(labelsize=tick_font_size)\n",
    "        cbar.set_label(cbar.ax.get_ylabel(), fontsize=label_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a square based on center coordinates and side size\n",
    "def create_square(center, side_size):\n",
    "    x = [\n",
    "        center[0] - side_size / 2,\n",
    "        center[0] + side_size / 2,\n",
    "        center[0] + side_size / 2,\n",
    "        center[0] - side_size / 2,\n",
    "        center[0] - side_size / 2,\n",
    "    ]\n",
    "    y = [\n",
    "        center[1] - side_size / 2,\n",
    "        center[1] - side_size / 2,\n",
    "        center[1] + side_size / 2,\n",
    "        center[1] + side_size / 2,\n",
    "        center[1] - side_size / 2,\n",
    "    ]\n",
    "    z = [0, 0, 0, 0, 0]  # All z-coordinates are set to 0 to align with the xy-plane\n",
    "\n",
    "    vertices = [(x[i], y[i], z[i]) for i in range(5)]\n",
    "    square = [[vertices[0], vertices[1], vertices[2], vertices[3]]]\n",
    "    return square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ed_axes(event_idx, charge, light):\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    ax3d = fig.add_subplot(121, projection=\"3d\")\n",
    "    ax2d = fig.add_subplot(122)\n",
    "    fig.suptitle(\n",
    "        f\"Event {event_idx} - Charge = {charge} {q_unit} - Light = {light} {light_unit}\"\n",
    "    )\n",
    "    grid_color = plt.rcParams[\"grid.color\"]\n",
    "\n",
    "    # Draw dead areas\n",
    "    for i, j in [(3, 3), (4, 4), (5, 4), (6, 4), (4, 2)]:\n",
    "        x = np.array([0, quadrant_size])\n",
    "        y = -np.array([0, quadrant_size])\n",
    "        ax2d.plot(\n",
    "            np.power(-1, flip_x)\n",
    "            * (x - detector_x / 2 + quadrant_size * (j - first_chip[1])),\n",
    "            (y + detector_y / 2 - quadrant_size * (i - first_chip[0])),\n",
    "            c=grid_color,\n",
    "            lw=1,\n",
    "        )\n",
    "        if i == 4 and j == 2:\n",
    "            x = np.array([quadrant_size / 2, 0])\n",
    "            y = -np.array([quadrant_size, quadrant_size / 2])\n",
    "        ax2d.plot(\n",
    "            np.power(-1, flip_x)\n",
    "            * (x[::-1] - detector_x / 2 + quadrant_size * (j - first_chip[1])),\n",
    "            (y + detector_y / 2 - quadrant_size * (i - first_chip[0])),\n",
    "            c=grid_color,\n",
    "            lw=1,\n",
    "        )\n",
    "\n",
    "    # Adjust axes\n",
    "    for ax in [ax3d, ax2d]:\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        ax.set_xlim([-detector_x / 2, detector_x / 2])\n",
    "        ax.set_ylim([-detector_y / 2, detector_y / 2])\n",
    "        ax.set_xlabel(f\"x [{xy_unit}]\")\n",
    "        ax.set_ylabel(f\"y [{xy_unit}]\")\n",
    "        ax.set_xticks(\n",
    "            np.linspace(\n",
    "                -detector_x / 2, detector_x / 2, (detector_x // quadrant_size) + 1\n",
    "            )\n",
    "        )\n",
    "        ax.set_yticks(\n",
    "            np.linspace(\n",
    "                -detector_y / 2, detector_y / 2, (detector_y // quadrant_size) + 1\n",
    "            )\n",
    "        )\n",
    "        ax.grid()\n",
    "\n",
    "    ax2d.xaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax2d.yaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax2d.tick_params(axis=\"both\", which=\"both\", right=True, top=True)\n",
    "\n",
    "    # Adjust z-axis\n",
    "    ax3d.set_zlabel(f\"z [{z_unit}]\")\n",
    "    # ax3d.zaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    return fig, (ax2d, ax3d)\n",
    "\n",
    "\n",
    "def event_display(\n",
    "    event_idx,\n",
    "    charge_df,\n",
    "    light_df,\n",
    "    plot_cyl=False,\n",
    "):\n",
    "    if len(charge_df) < 2:\n",
    "        return None\n",
    "\n",
    "    # Plot the hits\n",
    "    fig, axes = create_ed_axes(\n",
    "        event_idx, round(sum(charge_df[\"q\"])), round(sum(light_df[light_variable]))\n",
    "    )\n",
    "    ax2d = axes[0]\n",
    "    ax3d = axes[1]\n",
    "\n",
    "    # Group by x and y coordinates and sum the z values\n",
    "    unique_points, indices = np.unique(\n",
    "        charge_df[[\"x\", \"y\"]], axis=0, return_inverse=True\n",
    "    )\n",
    "    q_sum = np.bincount(indices, weights=charge_df[\"q\"])\n",
    "\n",
    "    # Plot the hits\n",
    "    plot3d = ax3d.scatter(\n",
    "        charge_df[\"x\"],\n",
    "        charge_df[\"y\"],\n",
    "        charge_df[\"z\"],\n",
    "        c=charge_df[\"q\"],\n",
    "        marker=\"s\",\n",
    "        s=30,\n",
    "        vmin=q_sum.min(),\n",
    "        vmax=q_sum.max(),\n",
    "    )\n",
    "    plot2d = ax2d.scatter(\n",
    "        unique_points[:, 0],\n",
    "        unique_points[:, 1],\n",
    "        c=q_sum,\n",
    "        marker=\"s\",\n",
    "        s=40,\n",
    "        vmin=q_sum.min(),\n",
    "        vmax=q_sum.max(),\n",
    "    )\n",
    "    cbar = plt.colorbar(plot2d)\n",
    "    cbar.set_label(f\"charge [{q_unit}]\")\n",
    "\n",
    "    # Cluster the hits\n",
    "    labels = cluster_hits(charge_df[[\"x\", \"y\", \"z\"]].to_numpy())\n",
    "\n",
    "    # Fit clusters\n",
    "    metrics = fit_hit_clusters(\n",
    "        charge_df[[\"x\", \"y\", \"z\"]].to_numpy(),\n",
    "        charge_df[\"q\"].to_numpy(),\n",
    "        labels,\n",
    "        ax2d,\n",
    "        ax3d,\n",
    "        plot_cyl,\n",
    "    )\n",
    "\n",
    "    # Draw missing SiPMs\n",
    "    grid_color = plt.rcParams[\"grid.color\"]\n",
    "\n",
    "    # Draw SiPMs\n",
    "    sipm_plot = ax2d.scatter(\n",
    "        light_df[\"x\"],\n",
    "        light_df[\"y\"],\n",
    "        c=light_df[light_variable],\n",
    "        marker=\"s\",\n",
    "        s=200,\n",
    "        linewidths=1.5,\n",
    "        edgecolors=grid_color,\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "    # Draw SiPMs\n",
    "    side_size = 6\n",
    "    vertices_x = np.array([1, 1, -1, -1, 1]) * side_size / 2\n",
    "    vertices_y = np.array([1, -1, -1, 1, 1]) * side_size / 2\n",
    "    light_xy = light_df[[\"x\", \"y\"]].apply(tuple, axis=1)\n",
    "    for missing_index in range(20):\n",
    "        col = -48 + (missing_index % 4) * 32\n",
    "        row = 64 - (missing_index // 4) * 32\n",
    "        square = create_square((col, row), side_size)\n",
    "        if not light_xy.isin([(col, row)]).any():\n",
    "            ax2d.fill(col + vertices_x, vertices_y + row, c=grid_color, zorder=5)\n",
    "            ax3d.add_collection3d(Poly3DCollection(square, color=grid_color))\n",
    "        else:\n",
    "            ax3d.add_collection3d(\n",
    "                Poly3DCollection(\n",
    "                    square,\n",
    "                    facecolors=sipm_plot.to_rgba(\n",
    "                        light_df[light_variable][light_xy == (col, row)]\n",
    "                    ),\n",
    "                    linewidths=0.5,\n",
    "                    edgecolors=grid_color,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    sipm_cbar = plt.colorbar(sipm_plot)\n",
    "    sipm_cbar.set_label(rf\"Light {light_variable} [{light_unit}]\")\n",
    "\n",
    "    ax3d.set_zlim([0, ax3d.get_zlim()[1]])\n",
    "    # ax3d.view_init(160, 110, -85)\n",
    "    ax3d.view_init(30, 20, 100)\n",
    "    # ax3d.view_init(0, 0, 0)\n",
    "    # ax3d.view_init(0, 0, 90)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_figures:\n",
    "        os.makedirs(f\"{file_label}/{event_idx}\", exist_ok=True)\n",
    "        fig.savefig(\n",
    "            f\"{file_label}/{event_idx}/event_{event_idx}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fake_data(z_range, buffer=1):\n",
    "    fake_data = generate_dead_area(z_range, buffer)\n",
    "    fake_x, fake_y, fake_z = fake_data[:, 0], fake_data[:, 1], fake_data[:, 2]\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.scatter(fake_x, fake_y, marker=\"s\", s=20)\n",
    "    ax.set_xlim([-detector_x / 2, detector_x / 2])\n",
    "    ax.set_ylim([-detector_y / 2, detector_y / 2])\n",
    "    ax.set_xlabel(f\"x [{xy_unit}]\")\n",
    "    ax.set_ylabel(f\"y [{xy_unit}]\")\n",
    "    ax.set_xticks(np.linspace(-detector_x / 2, detector_x / 2, 5))\n",
    "    ax.set_yticks(np.linspace(-detector_y / 2, detector_y / 2, 6))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax.grid()\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", top=True, right=True)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{path_prefix}/fake_data_map.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dQ versus X\n",
    "def plot_dQ(dQ_array, event_idx, track_idx, dh, interpolate=False):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax_twinx = ax.twinx()\n",
    "\n",
    "    fig.suptitle(\n",
    "        rf\"Event {event_idx} - Track {track_idx} - $dx = {round(dh,2)}$ {dh_unit}\"\n",
    "    )\n",
    "\n",
    "    mean_dQ = np.mean(dQ_array[dQ_array > 0])\n",
    "    non_zero_indices = np.where(dQ_array > 0)[0]\n",
    "\n",
    "    # Check if there are non-zero values in dQ_array\n",
    "    if non_zero_indices.size > 0:\n",
    "        # Find the first non-zero index and add 2 indices before it\n",
    "        first_index = max(non_zero_indices[0] - 2, 0)\n",
    "\n",
    "        # Find the last non-zero index and add 2 indices after it\n",
    "        last_index = min(non_zero_indices[-1] + 2, len(dQ_array))\n",
    "\n",
    "        new_dQ_array = dQ_array.copy()[first_index:last_index]\n",
    "\n",
    "        if interpolate:\n",
    "            new_dQ_array[1:-1] = np.where(\n",
    "                new_dQ_array[1:-1] == 0,\n",
    "                mean_dQ,\n",
    "                new_dQ_array[1:-1],\n",
    "            )\n",
    "\n",
    "        dQ_array = new_dQ_array\n",
    "\n",
    "    ax.axhline(\n",
    "        mean_dQ / dh,\n",
    "        ls=\"--\",\n",
    "        c=\"red\",\n",
    "        label=rf\"Mean = ${round(mean_dQ/dh,2)}$ {q_unit} {dh_unit}$^{{-1}}$\",\n",
    "        lw=1,\n",
    "    )\n",
    "    x_range = np.arange(0, len(dQ_array) * dh, dh)[: len(dQ_array)]\n",
    "\n",
    "    ax.step(x_range, dQ_array / dh, where=\"mid\")\n",
    "    ax.set_xlabel(rf\"$x$ [{dh_unit}]\")\n",
    "    ax.set_ylabel(rf\"$dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "\n",
    "    ax_twinx.step(x_range, np.cumsum(dQ_array), color=\"C1\", where=\"mid\")\n",
    "    ax_twinx.set_ylabel(f\"Q [{q_unit}]\")\n",
    "\n",
    "    for axes in [ax, ax_twinx]:\n",
    "        set_common_ax_options(axes)\n",
    "\n",
    "    h1, l1 = ax.get_legend_handles_labels()\n",
    "    ax_twinx.legend(h1, l1, loc=\"lower center\")\n",
    "\n",
    "    ax.legend(loc=\"lower center\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_figures:\n",
    "        os.makedirs(f\"{file_label}/{event_idx}\", exist_ok=True)\n",
    "        fig.savefig(\n",
    "            f\"{file_label}/{event_idx}/dQ_E{event_idx}_T{track_idx}_{round(dh,2)}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_track_stats(\n",
    "    metrics,\n",
    "    limit_xrange=True,\n",
    "    min_score=0.5,\n",
    "    empty_ratio_lims=(0, 1),\n",
    "    min_entries=2,\n",
    "    lognorm=True,\n",
    "    profile=False,\n",
    "    bins=[40, 40],\n",
    "):\n",
    "    track_mean_dQdx = []\n",
    "    track_std_dQdx = []\n",
    "    track_length = []\n",
    "    track_score = []\n",
    "    track_z = []\n",
    "    dQdx_list = []\n",
    "\n",
    "    empty_count = 0\n",
    "    short_count = 0\n",
    "    for entry in metrics.values():\n",
    "        for track, values in entry.items():\n",
    "            if isinstance(track, str) or track <= 0:\n",
    "                continue\n",
    "\n",
    "            dQ = values[\"dQ\"]\n",
    "            dx = values[\"dx\"]\n",
    "            non_zero_mask = np.where(dQ > 0)[0]\n",
    "\n",
    "            if len(dQ[non_zero_mask]) < min_entries:\n",
    "                short_count += 1\n",
    "                continue\n",
    "\n",
    "            empty_ratio = sum(dQ[non_zero_mask[0] : non_zero_mask[-1] + 1] == 0) / (\n",
    "                non_zero_mask[-1] - non_zero_mask[0] + 1\n",
    "            )\n",
    "\n",
    "            if empty_ratio > empty_ratio_lims[1] or empty_ratio < empty_ratio_lims[0]:\n",
    "                empty_count += 1\n",
    "                continue\n",
    "\n",
    "            dQdx = dQ[non_zero_mask[0] : non_zero_mask[-1] + 1] / dx\n",
    "            x_range = np.arange(0, len(dQdx) * dx, dx)[: len(dQdx)]\n",
    "            dQdx_list.append(pd.Series(dQdx, index=x_range))\n",
    "\n",
    "            non_zero_mask = non_zero_mask[non_zero_mask[0] : non_zero_mask[-1] + 1]\n",
    "            track_mean_dQdx.append(np.mean(dQdx[dQdx > 0]))\n",
    "            track_std_dQdx.append(np.std(dQdx[dQdx > 0]))\n",
    "            track_length.append(values[\"Fit_norm\"])\n",
    "            track_score.append(values[\"RANSAC_score\"])\n",
    "            track_z.append(values[\"Fit_line\"].point[2])\n",
    "\n",
    "    print(f\"Tracks with dead area outside {empty_ratio_lims} interval: {empty_count}\")\n",
    "    print(f\"Tracks with less than {min_entries} entries: {short_count}\")\n",
    "\n",
    "    track_mean_dQdx = pd.Series(track_mean_dQdx)\n",
    "    track_std_dQdx = pd.Series(track_std_dQdx)\n",
    "    track_length = pd.Series(track_length)\n",
    "    track_score = pd.Series(track_score)\n",
    "    track_z = pd.Series(track_z)\n",
    "    mask = (\n",
    "        track_mean_dQdx.notna()\n",
    "        * track_length.notna()\n",
    "        * track_score.notna()\n",
    "        * track_z.notna()\n",
    "    )\n",
    "\n",
    "    print(f\"Remaining tracks: {sum(mask)}\")\n",
    "\n",
    "    track_mean_dQdx = track_mean_dQdx[mask]\n",
    "    track_std_dQdx = track_std_dQdx[mask]\n",
    "    track_length = track_length[mask]\n",
    "    track_score = track_score[mask]\n",
    "    track_z = track_z[mask]\n",
    "    track_cv_dQdx = track_std_dQdx / track_mean_dQdx\n",
    "    dQdx_list = [series for i, series in enumerate(dQdx_list) if mask[i]]\n",
    "\n",
    "    score_mask = (track_score >= min_score).to_numpy()\n",
    "    score_bool = (1 - score_mask).sum() > 0\n",
    "\n",
    "    print(f\"Tracks with score < {min_score}: {sum(mask)-sum(score_mask)}\")\n",
    "\n",
    "    print(f\"Remaining_tracks: {sum(score_mask)}\")\n",
    "\n",
    "    # 1D histograms\n",
    "    fig1 = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    ax11 = fig1.add_subplot(121)\n",
    "    ax12 = fig1.add_subplot(122)\n",
    "\n",
    "    n_all11, bins_all11, patches_all11 = ax11.hist(\n",
    "        track_mean_dQdx, bins=bins[0], label=\"All tracks\"\n",
    "    )\n",
    "\n",
    "    n_all12, bins_all12, patches_all12 = ax12.hist(\n",
    "        track_length, bins=bins[0], label=\"All tracks\"\n",
    "    )\n",
    "\n",
    "    if score_bool:\n",
    "        n11, edges11, patches11 = ax11.hist(\n",
    "            track_mean_dQdx[score_mask],\n",
    "            bins=bins_all11,\n",
    "            label=rf\"Score $\\geq {min_score}$\",\n",
    "        )\n",
    "        ax12.hist(\n",
    "            track_length[score_mask],\n",
    "            bins=bins_all12,\n",
    "            label=rf\"Score $\\geq {min_score}$\",\n",
    "        )\n",
    "\n",
    "    ax11.set_xlabel(rf\"Mean $dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "    ax11.set_title(f\"{len(track_mean_dQdx)} tracks\")\n",
    "    ax12.set_title(f\"{len(track_length)} tracks\")\n",
    "\n",
    "    # 2D histograms\n",
    "    def hist2d(x, y, ax, bins, lognorm, fit=\"Log\", profile=False):\n",
    "        if profile:\n",
    "            hist, x_edges, y_edges = np.histogram2d(x, y, bins=bins)\n",
    "\n",
    "            y_means = [\n",
    "                np.mean(y[(x >= x_edges[i]) & (x < x_edges[i + 1])])\n",
    "                for i in range(len(x_edges) - 1)\n",
    "            ]\n",
    "            y_stds = [\n",
    "                np.std(y[(x >= x_edges[i]) & (x < x_edges[i + 1])])\n",
    "                for i in range(len(x_edges) - 1)\n",
    "            ]\n",
    "            x_values = (x_edges[1:] + x_edges[:-1]) / 2\n",
    "            bin_widths = [\n",
    "                (x_edges[i + 1] - x_edges[i]) / 2 for i in range(len(x_edges) - 1)\n",
    "            ]\n",
    "            ax.errorbar(x_values, y_means, yerr=y_stds, xerr=bin_widths, fmt=\"o\")\n",
    "\n",
    "        else:\n",
    "            hist2d = ax.hist2d(\n",
    "                x,\n",
    "                y,\n",
    "                bins=bins,\n",
    "                cmin=1,\n",
    "                norm=LogNorm() if lognorm else None,\n",
    "            )\n",
    "        if fit == \"Log\":\n",
    "            x_fit = np.log(x)\n",
    "        elif fit == \"Linear\":\n",
    "            x_fit = x\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            fit_p = np.polyfit(x_fit, y, 1)\n",
    "        except:\n",
    "            if fit == \"Log\":\n",
    "                x_fit = x  # Try linear fit as a fallback\n",
    "                fit = \"Linear\"\n",
    "            elif fit == \"Linear\":\n",
    "                x_fit = np.log(x)  # Try log fit as a fallback\n",
    "                fit = \"Log\"\n",
    "            try:\n",
    "                fit_p = np.polyfit(x_fit, y, 1)\n",
    "            except:\n",
    "                return\n",
    "\n",
    "        p = np.poly1d(fit_p)\n",
    "        x_plot = np.arange(min(x), max(x), 1)\n",
    "\n",
    "        if fit == \"Log\":\n",
    "            y_plot = p(np.log(x_plot))\n",
    "        else:\n",
    "            y_plot = p(x_plot)\n",
    "\n",
    "        ax.plot(x_plot, y_plot, c=\"salmon\", ls=\"-\", label=f\"{fit} fit\")\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14, 6))\n",
    "    ax21 = fig2.add_subplot(121)\n",
    "    ax22 = fig2.add_subplot(122)\n",
    "\n",
    "    fig2.suptitle(f\"{len(track_mean_dQdx)} tracks\")\n",
    "    ax21.set_ylabel(rf\"Mean $dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "    ax21.set_title(\"Mean dQ/dx vs. Track length\")\n",
    "    ax22.set_ylabel(rf\"$dQ/dx$ CV\")\n",
    "    ax22.set_title(\"dQ/dx CV vs. Track length\")\n",
    "\n",
    "    hist2d21 = hist2d(\n",
    "        track_length, track_mean_dQdx, ax21, bins, lognorm, fit=\"Log\", profile=profile\n",
    "    )\n",
    "\n",
    "    hist2d22 = hist2d(\n",
    "        track_length, track_cv_dQdx, ax22, bins, lognorm, fit=\"Linear\", profile=profile\n",
    "    )\n",
    "\n",
    "    fig4 = plt.figure(figsize=(7, 6))\n",
    "    ax4 = fig4.add_subplot(111)\n",
    "    ax4.set_ylabel(f\"Fit score\")\n",
    "    ax4.set_title(\"Fit score vs. Track length\")\n",
    "\n",
    "    hist2d4 = hist2d(\n",
    "        track_length,\n",
    "        track_score,\n",
    "        ax4,\n",
    "        [bins[0], 40],\n",
    "        lognorm,\n",
    "        fit=\"Log\",\n",
    "        profile=profile,\n",
    "    )\n",
    "\n",
    "    cut_dQdx_series = pd.concat(\n",
    "        [series for i, series in enumerate(dQdx_list) if score_mask[i]]\n",
    "    )\n",
    "    cut_dQdx_series = cut_dQdx_series[cut_dQdx_series > 0].dropna().sort_index()\n",
    "    dQdx_series = pd.concat(dQdx_list)\n",
    "    dQdx_series = dQdx_series[dQdx_series > 0].dropna().sort_index()\n",
    "\n",
    "    fig5 = plt.figure(figsize=(7 + 7 * score_bool, 6))\n",
    "    ax51 = fig5.add_subplot(111 + 10 * score_bool)\n",
    "    ax51.set_ylabel(rf\"$dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "    ax51.set_xlabel(rf\"Residual range [{dh_unit}]\")\n",
    "    ax51.set_title(rf\"{len(track_mean_dQdx)} tracks\")\n",
    "\n",
    "    hist2d(\n",
    "        dQdx_series.index,\n",
    "        dQdx_series,\n",
    "        ax51,\n",
    "        bins,\n",
    "        lognorm,\n",
    "        fit=\"Linear\",\n",
    "        profile=profile,\n",
    "    )\n",
    "\n",
    "    fig6 = plt.figure(figsize=(7 + 7 * score_bool, 6))\n",
    "    ax61 = fig6.add_subplot(111 + 10 * score_bool)\n",
    "    ax61.set_ylabel(rf\"Mean $dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "    ax61.set_xlabel(rf\"Anode distance [{z_unit}]\")\n",
    "    ax61.set_title(rf\"{len(track_z)} tracks\")\n",
    "\n",
    "    hist2d(track_z, track_mean_dQdx, ax61, bins, lognorm, fit=\"Linear\", profile=profile)\n",
    "\n",
    "    axes = [ax11, ax12, ax21, ax22, ax4, ax51, ax61]\n",
    "    figs = [fig1, fig2, fig4, fig5, fig6]\n",
    "\n",
    "    if score_bool:\n",
    "        # 2D histograms after RANSAC score cut\n",
    "        fig3 = plt.figure(figsize=(14, 6))\n",
    "        ax31 = fig3.add_subplot(121)\n",
    "        ax32 = fig3.add_subplot(122)\n",
    "        ax31.set_ylabel(rf\"Mean $dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "        ax31.set_title(rf\"Mean dQ/dx vs. Track length\")\n",
    "        ax32.set_ylabel(rf\"$dQ/dx$ CV\")\n",
    "        ax32.set_title(rf\"dQ/dx CV vs. Track length\")\n",
    "        fig3.suptitle(\n",
    "            rf\"Fit score $\\geq {min_score}$ ({round(sum(score_mask)/len(score_mask)*100)}% of tracks)\"\n",
    "        )\n",
    "\n",
    "        figs.append(fig3)\n",
    "        axes.extend([ax31, ax32])\n",
    "\n",
    "        hist2d31 = hist2d(\n",
    "            track_length[score_mask],\n",
    "            track_mean_dQdx[score_mask],\n",
    "            ax31,\n",
    "            bins,\n",
    "            lognorm,\n",
    "            fit=\"Log\",\n",
    "            profile=profile,\n",
    "        )\n",
    "\n",
    "        hist2d32 = hist2d(\n",
    "            track_length[score_mask],\n",
    "            track_cv_dQdx[score_mask],\n",
    "            ax32,\n",
    "            bins,\n",
    "            lognorm,\n",
    "            fit=\"Linear\",\n",
    "            profile=profile,\n",
    "        )\n",
    "\n",
    "        ax52 = fig5.add_subplot(122)\n",
    "        axes.append(ax52)\n",
    "        ax52.set_ylabel(rf\"$dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "        ax52.set_xlabel(rf\"Residual range [{dh_unit}]\")\n",
    "        ax52.set_title(\n",
    "            rf\"Fit score $\\geq {min_score}$ ({round(sum(score_mask)/len(score_mask)*100)}% of tracks)\"\n",
    "        )\n",
    "        fig5.suptitle(\"dQ/dx vs. Residual range\")\n",
    "\n",
    "        hist2d(\n",
    "            cut_dQdx_series.index,\n",
    "            cut_dQdx_series,\n",
    "            ax52,\n",
    "            bins,\n",
    "            lognorm,\n",
    "            fit=\"Linear\",\n",
    "            profile=profile,\n",
    "        )\n",
    "\n",
    "        ax62 = fig6.add_subplot(122)\n",
    "        axes.append(ax62)\n",
    "        ax62.set_ylabel(rf\"Mean $dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "        ax62.set_xlabel(rf\"Mean anode distance [{z_unit}]\")\n",
    "        ax62.set_title(\n",
    "            rf\"Fit score $\\geq {min_score}$ ({round(sum(score_mask)/len(score_mask)*100)}% of tracks)\"\n",
    "        )\n",
    "        fig6.suptitle(\"Mean dQ/dx vs. Mean anode distance\")\n",
    "\n",
    "        hist2d(\n",
    "            track_z[score_mask],\n",
    "            track_mean_dQdx[score_mask],\n",
    "            ax62,\n",
    "            bins,\n",
    "            lognorm,\n",
    "            fit=\"Linear\",\n",
    "            profile=profile,\n",
    "        )\n",
    "\n",
    "    max_track_legth = np.sqrt(detector_x**2 + detector_y**2 + detector_z**2)\n",
    "    max_track_legth_xy = np.sqrt(detector_x**2 + detector_y**2)\n",
    "    print(\"Max possible track length\", round(max_track_legth, 2), \"mm\")\n",
    "    print(\"Max possible track lengt on xy plane\", round(max_track_legth_xy, 2), \"mm\")\n",
    "    print(\"Max possible vertical track length\", detector_y, \"mm\")\n",
    "\n",
    "    for ax in axes:\n",
    "        set_common_ax_options(ax)\n",
    "        if ax == ax11 or ax == ax12:\n",
    "            ax.set_ylabel(\"Counts\")\n",
    "        if ax != ax11:\n",
    "            if not (\n",
    "                ax == ax51 or ax == ax61 or (score_bool and (ax == ax52 or ax == ax62))\n",
    "            ):\n",
    "                ax.set_xlabel(f\"Track length [{dh_unit}]\")\n",
    "            if max(track_length) > detector_y:\n",
    "                ax.axvline(detector_y, c=\"g\", ls=\"--\", label=\"Max vertical length\")\n",
    "            if max(track_length) > max_track_legth_xy:\n",
    "                ax.axvline(\n",
    "                    max_track_legth_xy, c=\"orange\", ls=\"--\", label=r\"Max length in $xy$\"\n",
    "                )\n",
    "            if max(track_length) > max_track_legth:\n",
    "                ax.axvline(max_track_legth, c=\"r\", ls=\"--\", label=\"Max length\")\n",
    "\n",
    "            if ax != ax12:\n",
    "                if limit_xrange:\n",
    "                    xlim = ax.get_xlim()\n",
    "                    ax.set_xlim(xlim[0], min(max_track_legth + 10, xlim[1]))\n",
    "                cbar = plt.colorbar(ax.collections[0])\n",
    "                cbar.set_label(\"Counts\" + (\" [log]\" if lognorm else \"\"))\n",
    "        if not (not score_bool and ax == ax11):\n",
    "            ax.legend(loc=\"lower right\" if ax == ax4 else \"upper right\")\n",
    "\n",
    "    for fig in figs:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    if save_figures:\n",
    "        entries = len(track_mean_dQdx)\n",
    "        fig1.savefig(\n",
    "            f\"{file_label}/track_stats_1D_hist_{file_label}_{entries}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig2.savefig(\n",
    "            f\"{file_label}/track_stats_2D_hist_{file_label}_{entries}{'_profile' if profile else ''}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig4.savefig(\n",
    "            f\"{file_label}/track_stats_score_{file_label}_{entries}{'_profile' if profile else ''}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig5.savefig(\n",
    "            f\"{file_label}/track_stats_dQdx_{file_label}_{entries}{'_profile' if profile else ''}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig6.savefig(\n",
    "            f\"{file_label}/track_stats_dQdx_z_{file_label}_{entries}{'_profile' if profile else ''}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        if score_bool:\n",
    "            fig3.savefig(\n",
    "                f\"{file_label}/track_stats_2D_hist_cut_{file_label}_{entries}{'_profile' if profile else ''}.pdf\",\n",
    "                dpi=300,\n",
    "                bbox_inches=\"tight\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracks and light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_light_geo_stats(\n",
    "    metrics,\n",
    "    limit_xrange=False,\n",
    "    light_max=None,\n",
    "    min_count_ratio=0.99,\n",
    "    max_std_ratio=0.2,\n",
    "    single_track=True,\n",
    "    lognorm=True,\n",
    "):\n",
    "    sipm_distance = []\n",
    "    sipm_angle = []\n",
    "    sipm_light = []\n",
    "\n",
    "    for metric in metrics.values():\n",
    "        if single_track and len(metric.keys()) > 1 + non_track_keys:\n",
    "            continue\n",
    "        for track_idx, values in metric.items():\n",
    "            if not isinstance(track_idx, str) and track_idx > 0:\n",
    "                sipms = values[\"SiPM\"]\n",
    "                for light in sipms.values():\n",
    "                    sipm_distance.append(light[\"distance\"])\n",
    "                    sipm_angle.append(light[\"angle\"])\n",
    "                    sipm_light.append(light[light_variable])\n",
    "\n",
    "    sipm_distance = np.array(sipm_distance)\n",
    "    sipm_angle = np.array(sipm_angle)\n",
    "    sipm_light = np.array(sipm_light)\n",
    "\n",
    "    max_distance = np.sqrt(detector_x**2 + detector_y**2 + detector_z**2)\n",
    "    print(\"Max possible distance to track\", round(max_distance, 2), \"mm\")\n",
    "    print(\"Drift distance\", detector_z, \"mm\")\n",
    "\n",
    "    sipm_distance = sipm_distance[~np.isnan(sipm_light) & (sipm_light > 0)]\n",
    "    sipm_angle = sipm_angle[~np.isnan(sipm_light) & (sipm_light > 0)]\n",
    "    sipm_light = sipm_light[~np.isnan(sipm_light) & (sipm_light > 0)]\n",
    "\n",
    "    fig1 = plt.figure(figsize=(7, 6))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "\n",
    "    vline = max_std(\n",
    "        sipm_light,\n",
    "        ax1,\n",
    "        array_max=light_max,\n",
    "        max_std_ratio=max_std_ratio,\n",
    "        min_count_ratio=min_count_ratio,\n",
    "    )\n",
    "    bins = vline\n",
    "\n",
    "    ax1.set_xlabel(\"Max light integral\")\n",
    "    ax1.set_ylabel(\"Normalized value\")\n",
    "\n",
    "    fig1.suptitle(\"Light integral distribution\")\n",
    "\n",
    "    sipm_distance = sipm_distance[(sipm_light <= vline)]\n",
    "    sipm_angle = sipm_angle[(sipm_light <= vline)]\n",
    "    sipm_light = sipm_light[(sipm_light <= vline)]\n",
    "    sipm_angle = np.degrees(sipm_angle)\n",
    "\n",
    "    fig2, ax2 = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    axes = np.array(ax2)\n",
    "\n",
    "    n2, x_edges2, y_edges2, image2 = ax2.hist2d(\n",
    "        sipm_distance,\n",
    "        sipm_angle,\n",
    "        weights=abs(sipm_light),\n",
    "        bins=bins,\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )\n",
    "\n",
    "    def triangle_calc(height, base):\n",
    "        # Calculate the angle θ\n",
    "        return np.degrees(2 * np.arctan((base / 2) / height))\n",
    "\n",
    "    def inverse_triangle_calc(angle, height):\n",
    "        # Calculate the base\n",
    "        return 2 * height * np.tan(np.radians(angle / 2))\n",
    "\n",
    "    filtered_centers_x2, filtered_centers_y2, cluster_labels = cluster_hot_bins(\n",
    "        0.35, n2, x_edges2, y_edges2, scale=(3, 1), eps=8\n",
    "    )\n",
    "\n",
    "    # Create a LinearSegmentedColormap from the gradient\n",
    "    salmon_cmap = LinearSegmentedColormap.from_list(\n",
    "        \"salmon_cmap\",\n",
    "        [\n",
    "            to_rgba(\"darkred\"),\n",
    "            to_rgba(\"salmon\"),\n",
    "        ],\n",
    "        N=np.unique(cluster_labels).size - 1,\n",
    "    )\n",
    "\n",
    "    x2 = np.arange(min(sipm_distance), max(sipm_distance), 1)\n",
    "    for cluster_label in np.unique(cluster_labels):\n",
    "        if cluster_label == -1:\n",
    "            continue\n",
    "        fit2 = parameters, cov = curve_fit(\n",
    "            triangle_calc,\n",
    "            filtered_centers_x2[cluster_labels == cluster_label],\n",
    "            filtered_centers_y2[cluster_labels == cluster_label],\n",
    "            p0=[\n",
    "                inverse_triangle_calc(sipm_angle.mean(), sipm_distance.mean()),\n",
    "            ],\n",
    "        )\n",
    "        print(f\"Fit mean track length: {parameters[0]}\")\n",
    "\n",
    "        ax2.plot(\n",
    "            x2,\n",
    "            triangle_calc(x2, *parameters),\n",
    "            ls=\"-\",\n",
    "            c=salmon_cmap(cluster_label),\n",
    "            label=rf\"Fit: {parameters[0]:.0f}{dh_unit} track length\",\n",
    "        )\n",
    "    ax2.set_ylabel(f\"SiPM opening angle to track centre [deg]\")\n",
    "    cbar2 = plt.colorbar(image2)\n",
    "    cbar2.set_label(rf\"Light {light_variable} [{light_unit} - log]\")\n",
    "\n",
    "    fig2.suptitle(f\"SiPM level light distribution - {len(sipm_light)} entries\")\n",
    "\n",
    "    fig3, axes3 = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    axes = np.append(axes, axes3)\n",
    "\n",
    "    hist30 = axes3[0].hist2d(\n",
    "        sipm_distance,\n",
    "        sipm_light,\n",
    "        bins=bins,\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )\n",
    "    axes3[0].set_ylabel(f\"Light_{light_variable} [{light_unit}]\")\n",
    "    cbar30 = plt.colorbar(hist30[3])\n",
    "    cbar30.set_label(rf\"Counts [Log]\")\n",
    "\n",
    "    hist31 = axes3[1].hist2d(\n",
    "        sipm_angle, sipm_light, bins=bins, cmin=1, norm=LogNorm() if lognorm else None\n",
    "    )\n",
    "    axes3[1].set_xlabel(f\"SiPM opening angle to track [deg]\")\n",
    "    axes3[1].set_ylabel(f\"Light {light_variable} [{light_unit}]\")\n",
    "    cbar31 = plt.colorbar(hist31[3])\n",
    "    cbar31.set_label(rf\"Counts [Log]\")\n",
    "\n",
    "    fig3.suptitle(f\"SiPM level light distribution - {len(sipm_light)} entries\")\n",
    "\n",
    "    for ax in axes:\n",
    "        set_common_ax_options(ax)\n",
    "        if ax == ax2 or ax == axes3[0]:\n",
    "            if limit_xrange:\n",
    "                xlim = ax.get_xlim()\n",
    "                ax.set_xlim(xlim[0], min(max_distance + 10, xlim[1]))\n",
    "            if max(sipm_distance) > detector_z:\n",
    "                ax.axvline(detector_z, c=\"orange\", ls=\"--\", label=\"Drift distance\")\n",
    "            if max(sipm_distance) > max_distance:\n",
    "                ax.axvline(max_distance, c=\"r\", ls=\"--\", label=\"Max distance\")\n",
    "\n",
    "            ax.set_xlabel(f\"Distance from track centre [{dh_unit}]\")\n",
    "\n",
    "            ax.legend()\n",
    "\n",
    "    for fig in [fig1, fig2, fig3]:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    if save_figures:\n",
    "        entries = len(sipm_light)\n",
    "        fig1.savefig(\n",
    "            f\"{file_label}/light_geo_optimization_{file_label}_{entries}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig2.savefig(\n",
    "            f\"{file_label}/light_geo_2D_hist_{file_label}_{entries}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig3.savefig(\n",
    "            f\"{file_label}/light_geo_1D_hist_{file_label}_{entries}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_light_fit_stats(metrics):\n",
    "    cosine_df = pd.DataFrame(columns=[\"cosine\", \"threshold\", \"Light\", \"Charge\"])\n",
    "    for event, metric in metrics.items():\n",
    "        if \"Fit_line\" not in metric[\"SiPM\"]:\n",
    "            continue\n",
    "        light_track = metric[\"SiPM\"][\"Fit_line\"]\n",
    "        if len(metric.keys()) == non_track_keys + 1:\n",
    "            for idx, track in metric.items():\n",
    "                if isinstance(idx, str):\n",
    "                    continue\n",
    "                charge_track = track[\"Fit_line\"]\n",
    "                cross = charge_track.direction.cross(light_track.direction)\n",
    "                cosine = abs(\n",
    "                    charge_track.direction.cosine_similarity(light_track.direction)\n",
    "                )\n",
    "                cosine_df.loc[event] = [\n",
    "                    cosine,\n",
    "                    metric[\"SiPM\"][\"Fit_threshold\"],\n",
    "                    charge_track.direction,\n",
    "                    light_track.direction,\n",
    "                ]\n",
    "    entries = len(cosine_df)\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in range(0, int(cosine_df[\"threshold\"].max()), 10):\n",
    "        data = cosine_df[cosine_df[\"threshold\"] > i]\n",
    "        if len(data) > 0.005 * len(cosine_df):\n",
    "            data.hist(\n",
    "                \"cosine\",\n",
    "                ax=ax,\n",
    "                bins=np.linspace(0, 1, 11),\n",
    "                label=f\"Threshold: {i} {light_unit} - {len(cosine_df[cosine_df['threshold']>i])} entries\",\n",
    "            )\n",
    "    ax.set(\n",
    "        title=\"Cosine similarity between charge and light tracks\",\n",
    "        xlabel=\"Cosine similarity\",\n",
    "        ylabel=\"Counts\",\n",
    "    )\n",
    "    set_common_ax_options(ax)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    if save_figures:\n",
    "        fig.savefig(\n",
    "            f\"{file_label}/light_fit_{file_label}_{entries}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_vs_charge(\n",
    "    metrics,\n",
    "    light_max=None,\n",
    "    min_count_ratio=0.99,\n",
    "    max_std_ratio=0.5,\n",
    "    clusters=None,\n",
    "    bin_density=1,\n",
    "    log=(True, False),\n",
    "    p0=True,\n",
    "):\n",
    "    if isinstance(log, bool):\n",
    "        log = [log, log]\n",
    "\n",
    "    light_array = []\n",
    "    charge_array = []\n",
    "    for event, metric in metrics.items():\n",
    "        light_array.append(metric[\"Total_light\"])\n",
    "        charge_array.append(metric[\"Total_charge\"])\n",
    "\n",
    "    light_array = np.array(light_array)\n",
    "    charge_array = np.array(charge_array)\n",
    "\n",
    "    mask = (charge_array > 0) & (light_array > 0)\n",
    "    charge_array = charge_array[mask]\n",
    "    light_array = light_array[mask]\n",
    "\n",
    "    fig1 = plt.figure(figsize=(8, 6))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.set_xlabel(\"Max light integral\")\n",
    "    ax1.set_ylabel(\"Normalized value\")\n",
    "    fig1.suptitle(\"Light integral distribution\")\n",
    "    vline = max_std(\n",
    "        light_array,\n",
    "        ax1,\n",
    "        array_max=light_max,\n",
    "        min_count_ratio=min_count_ratio,\n",
    "        max_std_ratio=max_std_ratio,\n",
    "    )\n",
    "    bins = int(vline / 20)\n",
    "\n",
    "    charge_array = charge_array[(light_array <= vline)]\n",
    "    light_array = light_array[(light_array <= vline)]\n",
    "\n",
    "    def hist2d(x, y, ax, bins, log):\n",
    "        if log:\n",
    "            log_bins_x = np.exp(np.linspace(np.log(min(x) - 1), np.log(max(x)), bins))\n",
    "            log_bins_y = np.exp(np.linspace(np.log(min(y)), np.log(max(y)), bins))\n",
    "            bins = [log_bins_x, log_bins_y]\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        n, x_edges, y_edges, image = ax.hist2d(x, y, bins=bins, cmin=1)\n",
    "\n",
    "        # fit peak with curve_fit\n",
    "        # @latexify.function(use_math_symbols=True)\n",
    "        def fit_function(xy, amplitude, xo, yo, sigma_x, sigma_y):\n",
    "            x, y = xy\n",
    "            gauss = (\n",
    "                amplitude\n",
    "                * np.exp(-0.5 * ((x - xo) / sigma_x) ** 2)\n",
    "                / (sigma_x * np.sqrt(2 * np.pi))\n",
    "                * np.exp(-0.5 * ((y - yo) / sigma_y) ** 2)\n",
    "                / (sigma_y * np.sqrt(2 * np.pi))\n",
    "            )\n",
    "            return gauss\n",
    "\n",
    "        try:\n",
    "            bin_peaks = n.ravel(order=\"F\")\n",
    "            bin_peaks[np.isnan(bin_peaks)] = 0\n",
    "            x_bin_centers = 0.5 * (x_edges[1:] + x_edges[:-1])\n",
    "            y_bin_centers = 0.5 * (y_edges[1:] + y_edges[:-1])\n",
    "            x_bin_centers, y_bin_centers = np.array(\n",
    "                np.meshgrid(x_bin_centers, y_bin_centers)\n",
    "            )\n",
    "            x_bin_centers = x_bin_centers.ravel()\n",
    "            y_bin_centers = y_bin_centers.ravel()\n",
    "\n",
    "            parameters, cov_matrix = curve_fit(\n",
    "                fit_function,\n",
    "                (\n",
    "                    x_bin_centers / max(x_bin_centers),\n",
    "                    y_bin_centers / max(y_bin_centers),\n",
    "                ),\n",
    "                bin_peaks,\n",
    "                bounds=(0, np.inf),\n",
    "            )\n",
    "            plot_mesh = np.array(\n",
    "                np.meshgrid(\n",
    "                    np.linspace(min(x) / max(x), 1, len(x_bin_centers) * 5),\n",
    "                    np.linspace(min(y) / max(y), 1, len(y_bin_centers) * 5),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            z_plot = fit_function(plot_mesh, *parameters)\n",
    "\n",
    "            # print(latexify.get_latex(fit_function))\n",
    "            print(\"Parameters:\")\n",
    "            print(\n",
    "                \"\\n\".join(\n",
    "                    [\n",
    "                        f\"{name}: {value}\"\n",
    "                        for name, value in zip(\n",
    "                            [\n",
    "                                \"amplitude\",\n",
    "                                \"mu_x\",\n",
    "                                \"mu_y\",\n",
    "                                \"sigma_x\",\n",
    "                                \"sigma_y\",\n",
    "                                \"theta\",\n",
    "                            ],\n",
    "                            parameters,\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                \"\\n\",\n",
    "            )\n",
    "            contour = ax.contour(\n",
    "                plot_mesh[0] * max(x),\n",
    "                plot_mesh[1] * max(y),\n",
    "                z_plot,\n",
    "                norm=\"log\",\n",
    "                cmap=\"autumn\",\n",
    "                linewidths=1,\n",
    "                levels=[\n",
    "                    fit_function(\n",
    "                        (\n",
    "                            parameters[1] - 3 * parameters[3],\n",
    "                            parameters[2] - 3 * parameters[4],\n",
    "                        ),\n",
    "                        *parameters,\n",
    "                    ),\n",
    "                    fit_function(\n",
    "                        (\n",
    "                            parameters[1] - 2 * parameters[3],\n",
    "                            parameters[2] - 2 * parameters[4],\n",
    "                        ),\n",
    "                        *parameters,\n",
    "                    ),\n",
    "                    fit_function(\n",
    "                        (\n",
    "                            parameters[1] - 1 * parameters[3],\n",
    "                            parameters[2] - 1 * parameters[4],\n",
    "                        ),\n",
    "                        *parameters,\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "            fmt = {}\n",
    "            strs = [r\"$3\\sigma$\", r\"$2\\sigma$\", r\"$1\\sigma$\"]\n",
    "            for l, s in zip(contour.levels, strs):\n",
    "                fmt[l] = s\n",
    "\n",
    "            ax.clabel(contour, contour.levels, inline=True, fmt=fmt, fontsize=10)\n",
    "        except:\n",
    "            print(\"Fit failed\\n\")\n",
    "\n",
    "        ax.set_xlabel(f\"Total charge [{q_unit}{' - Log' if log else ''}]\")\n",
    "        ax.set_ylabel(\n",
    "            f\"Total Light {light_variable} [{light_unit}{' - Log' if log else ''}]\"\n",
    "        )\n",
    "        cbar = plt.colorbar(image)\n",
    "        cbar.set_label(rf\"Counts\")\n",
    "        set_common_ax_options(ax)\n",
    "\n",
    "        return n, x_edges, y_edges, image\n",
    "\n",
    "    def hist1d(array, ax, bin_density, log, p0):\n",
    "        # fit peak with curve_fit\n",
    "        # @latexify.function(use_math_symbols=True)\n",
    "        def fit_function(x, a, mu, sigma, b, c):\n",
    "            return (\n",
    "                # gaussian_part\n",
    "                a\n",
    "                * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "                / (sigma * np.sqrt(2 * np.pi))\n",
    "                # exponential_part\n",
    "                + b * np.exp(-c * x)\n",
    "            )\n",
    "\n",
    "        upper_bound = np.percentile(array, 95)\n",
    "        array = array[array < upper_bound]\n",
    "        if log:\n",
    "            ax.set_xscale(\"log\")\n",
    "            bins = np.exp(\n",
    "                np.linspace(\n",
    "                    np.log(min(array) - 1), np.log(upper_bound), int(50 * bin_density)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            bins = np.linspace(min(array), upper_bound, int(50 * bin_density))\n",
    "\n",
    "        n, edges, patches = ax.hist(\n",
    "            array, bins=bins, fill=False, ec=\"C0\", histtype=\"bar\"\n",
    "        )\n",
    "\n",
    "        peak_y = n.max()\n",
    "        peak_x = edges[n.argmax() : n.argmax() + 1].mean()\n",
    "        mean = array.mean()\n",
    "        median = np.median(array)\n",
    "\n",
    "        set_common_ax_options(ax)\n",
    "        if not log:\n",
    "            bin_centers = 0.5 * (edges[1:] + edges[:-1])\n",
    "            bin_centers = bin_centers[n > 0]\n",
    "            bin_peaks = n[n > 0]\n",
    "\n",
    "            try:\n",
    "                if p0 is True:\n",
    "                    p0 = [\n",
    "                        peak_y,\n",
    "                        max(peak_x / min(bin_centers), 1),\n",
    "                        0.04 * max(bin_centers) / max(peak_x, 1),\n",
    "                        peak_y,\n",
    "                        0.01,\n",
    "                    ]\n",
    "                parameters, cov_matrix = curve_fit(\n",
    "                    fit_function,\n",
    "                    bin_centers / min(bin_centers),\n",
    "                    bin_peaks,\n",
    "                    p0=p0,\n",
    "                    bounds=([0, 0, 0, 0, -np.inf], np.inf),\n",
    "                )\n",
    "                x_plot = np.linspace(min(array), max(array), len(bins) * 10)\n",
    "                y_plot = fit_function(x_plot / min(bin_centers), *parameters)\n",
    "\n",
    "                # print(latexify.get_latex(fit_function))\n",
    "                print(\"Parameters:\")\n",
    "                print(\n",
    "                    \"\\n\".join(\n",
    "                        [\n",
    "                            f\"{name}: {value}\"\n",
    "                            for name, value in zip(\n",
    "                                [\"a\", \"mu\", \"sigma\", \"b\", \"c\"], parameters\n",
    "                            )\n",
    "                        ]\n",
    "                    ),\n",
    "                    \"\\n\",\n",
    "                )\n",
    "                ax.plot(\n",
    "                    x_plot,\n",
    "                    y_plot,\n",
    "                    \"m\",\n",
    "                    label=rf\"Fit ($\\mu={parameters[1]*min(bin_centers):.2f}$)\",\n",
    "                )\n",
    "            except:\n",
    "                print(\"Fit failed\\n\")\n",
    "\n",
    "        ax.axvline(peak_x, c=\"r\", ls=\"--\", label=f\"Peak: {peak_x:.2f}\")\n",
    "        ax.axvline(median, c=\"orange\", ls=\"--\", label=f\"Median: {median:.2f}\")\n",
    "        ax.axvline(mean, c=\"g\", ls=\"--\", label=f\"Mean: {mean:.2f}\")\n",
    "\n",
    "        ax.set_ylabel(f\"Counts\")\n",
    "        # ax.set_xlim(min(array) - 2, edges3[(edges3 < upper_bound).argmin()])\n",
    "        ax.set_ylim(0, peak_y * 1.1)\n",
    "        ax.legend()\n",
    "\n",
    "    fig2 = plt.figure(figsize=(8, 6))\n",
    "    ax2 = plt.subplot(111)\n",
    "    n2d, xedges2d, yedges2d, image2d = hist2d(\n",
    "        charge_array, light_array, ax2, bins, log[0]\n",
    "    )\n",
    "    fig2.suptitle(f\"Event level Light vs. Charge - {len(charge_array)} events\")\n",
    "\n",
    "    fig3 = plt.figure(figsize=(8, 6))\n",
    "    ax3 = plt.subplot(111)\n",
    "    ratio = charge_array / light_array\n",
    "    hist1d(ratio, ax3, bin_density, log[1], p0)\n",
    "    ax3.set_xlabel(\n",
    "        f\"Event total charge / Light [{q_unit}/{light_unit}{' - Log' if log[1] else ''}]\"\n",
    "    )\n",
    "    fig3.suptitle(f\"Event level Charge vs. Light - {len(charge_array)} events\")\n",
    "\n",
    "    fig4, axes4 = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    hist1d(charge_array, axes4[0], bin_density, log[1], p0)\n",
    "    axes4[0].set_xlabel(f\"Event total charge [{q_unit}{' - Log' if log[1] else ''}]\")\n",
    "    hist1d(light_array, axes4[1], bin_density, log[1], p0)\n",
    "    axes4[1].set_xlabel(f\"Event total Light [{light_unit}{' - Log' if log[1] else ''}]\")\n",
    "    fig4.suptitle(f\"Event level Charge and Light - {len(charge_array)} events\")\n",
    "\n",
    "    figs = [fig1, fig2, fig3, fig4]\n",
    "    if clusters is None:\n",
    "        if log[0]:\n",
    "            temp_x, temp_y, cluster_labels = cluster_hot_bins(\n",
    "                0.3, n2d, np.log(xedges2d), np.log(yedges2d), eps=1\n",
    "            )\n",
    "        else:\n",
    "            temp_x, temp_y, cluster_labels = cluster_hot_bins(\n",
    "                0.3,\n",
    "                n2d,\n",
    "                xedges2d,\n",
    "                yedges2d,\n",
    "                eps=2,\n",
    "                scale=(np.diff(xedges2d).mean(), np.diff(yedges2d).mean()),\n",
    "            )\n",
    "        clusters = np.unique(cluster_labels).size - 1\n",
    "\n",
    "    if clusters > 1:\n",
    "        data = pd.DataFrame(np.log(charge_array), np.log(light_array))\n",
    "        kmeans = KMeans(n_clusters=clusters)\n",
    "        kmeans.fit(data)\n",
    "        labels = kmeans.predict(data) + 1\n",
    "        populations = np.unique(labels)\n",
    "\n",
    "        fig22, axes22 = plt.subplots(\n",
    "            len(populations), 1, figsize=(8, 6 * len(populations))\n",
    "        )\n",
    "\n",
    "        fig32, axes32 = plt.subplots(\n",
    "            len(populations), 1, figsize=(10, 6 * len(populations))\n",
    "        )\n",
    "\n",
    "        figs.extend([fig22, fig32])\n",
    "\n",
    "        for idx, label in enumerate(populations):\n",
    "            hist2d(\n",
    "                charge_array[labels == label],\n",
    "                light_array[labels == label],\n",
    "                axes22[idx],\n",
    "                bins,\n",
    "                log[0],\n",
    "            )\n",
    "            axes22[idx].set_title(f\"Population {label} - {sum(labels == label)} events\")\n",
    "\n",
    "            print(f\"population {label}:\")\n",
    "\n",
    "            ratio = charge_array[labels == label] / light_array[labels == label]\n",
    "            hist1d(ratio, axes32[idx], bin_density, log[1], p0)\n",
    "            axes32[idx].set_xlabel(\n",
    "                f\"Event total charge / Light [{q_unit}/{light_unit}{' - Log' if log[1] else ''}]\"\n",
    "            )\n",
    "            axes32[idx].set_title(f\"Population {label} - {sum(labels == label)} events\")\n",
    "\n",
    "    for fig in figs:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    if save_figures:\n",
    "        events = len(ratio)\n",
    "        fig1.savefig(\n",
    "            f\"{file_label}/light_vs_charge_optmization_{file_label}_{events}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig2.savefig(\n",
    "            f\"{file_label}/light_vs_charge_2D_hist_{file_label}_{events}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        fig3.savefig(\n",
    "            f\"{file_label}/light_vs_charge_ratio_{file_label}_{events}.pdf\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File handing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If match dictionary already exists for this file label, load it\n",
    "temp_filename = f\"{file_label}/match_dict_{file_label}.json\"\n",
    "if not rematch_events and os.path.isfile(temp_filename):\n",
    "    with open(temp_filename, \"r\") as f:\n",
    "        match_dict = json.load(f)\n",
    "        match_dict = {int(key): value for key, value in match_dict.items()}\n",
    "\n",
    "    print(\"Match_dict loaded from file\")\n",
    "\n",
    "del temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_filename = f\"{file_label}/charge_df_{file_label}.bz2\"\n",
    "if not reload_files and os.path.isfile(temp_filename):\n",
    "    charge_df = pd.read_csv(temp_filename, index_col=0)\n",
    "    if not event_list is None:\n",
    "        charge_df = charge_df.loc[event_list.intersection(charge_df.index)]\n",
    "    # for column in :\n",
    "    charge_df[charge_df.columns[9:]] = charge_df[charge_df.columns[9:]].applymap(\n",
    "        lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    "    )\n",
    "else:\n",
    "    charge_df = load_charge(charge_file, events=event_list)\n",
    "\n",
    "del temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up charge dataframe\n",
    "\n",
    "# Remove events with negative charge hits and without light trigger\n",
    "charge_mask = (\n",
    "    charge_df[\"event_hits_q\"].apply(tuple).explode().groupby(\"eventID\").min() > 0\n",
    ") * (charge_df[\"trigID\"].apply(len) > 0)\n",
    "charge_df = charge_df[charge_mask]\n",
    "\n",
    "print(\n",
    "    f\"Removed charge events: {charge_mask.count()-charge_mask.sum()}/{charge_mask.count()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If match dictionary already loaded, match loaded charge events to light events before loading light events.\n",
    "light_event_list = None\n",
    "if not match_dict == {}:\n",
    "    light_event_list = ak.flatten(\n",
    "        [\n",
    "            match_dict.get(event, [])\n",
    "            for event in charge_df.index\n",
    "            if event_list is None or event in event_list\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"{len(light_event_list)} light events to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_filename = f\"{file_label}/light_df_{file_label}.bz2\"\n",
    "# Load light events using light_event_list if loaded via match dictionary\n",
    "if not reload_files and os.path.isfile(temp_filename):\n",
    "    light_df = pd.read_csv(temp_filename, index_col=0)\n",
    "    if not light_event_list is None:\n",
    "        light_df = light_df[light_df[\"event\"].isin(light_event_list)]\n",
    "\n",
    "else:\n",
    "    light_df = load_light(\n",
    "        light_file, deco=\"deco\" in light_file, events=light_event_list\n",
    "    )\n",
    "\n",
    "print(f\"{light_df['event'].nunique()} light events loaded.\")\n",
    "del temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up light dataframe\n",
    "\n",
    "# If match dictionary not yet loaded, create it\n",
    "if match_dict == {} or rematch_events:\n",
    "    match_dict = match_events(charge_df, light_df)\n",
    "\n",
    "    # Remove light events without charge event match\n",
    "    light_events = np.unique(ak.flatten(match_dict.values()))\n",
    "    light_df = light_df[light_df[\"event\"].isin(light_events)]\n",
    "\n",
    "    print(\n",
    "        f\"Remaining light events with charge event match: {light_df['event'].nunique()}\"\n",
    "    )\n",
    "\n",
    "# Remove charge events without associated light event\n",
    "charge_df = charge_df.loc[match_dict.keys()]\n",
    "\n",
    "print(f\"Remaining charge events with light match: {len(charge_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip x axis according to flag\n",
    "\n",
    "charge_df[\"event_hits_x\"] = charge_df[\"event_hits_x\"].apply(\n",
    "    lambda x: [np.power(-1, flip_x) * i for i in x]\n",
    ")\n",
    "light_df[\"x\"] = light_df[\"x\"].apply(lambda x: np.power(-1, flip_x) * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(file_label, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save files if all events were considered, i.e. event_list is None\n",
    "if event_list is None:\n",
    "    charge_df.to_csv(f\"{file_label}/charge_df_{file_label}.bz2\")\n",
    "    light_df.to_csv(f\"{file_label}/light_df_{file_label}.bz2\")\n",
    "    with open(f\"{file_label}/match_dict_{file_label}.json\", \"w\") as f:\n",
    "        json.dump(match_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sipm_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trigger time distribution\")\n",
    "charge_df[\"trig_time\"].apply(np.mean).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Event duration in {time_unit}\")\n",
    "charge_df[\"event_duration\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Charge per hit in {q_unit}\")\n",
    "(charge_df[\"event_q\"] / charge_df[\"event_nhits\"]).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Charge per hit per event in {q_unit}\")\n",
    "(charge_df[\"event_q\"] / charge_df[\"event_nhits\"]).to_frame().reset_index().plot.scatter(\n",
    "    x=\"eventID\", y=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Event charge in {q_unit}\")\n",
    "charge_df[\"event_q\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hits q in {q_unit}\")\n",
    "charge_df[\"event_hits_q\"].apply(tuple).explode().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hits z in {z_unit}\")\n",
    "charge_df[\"event_hits_z\"].apply(tuple).explode().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_df[light_variable].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake data map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fake_data([1], buffer=(xy_epsilon - 1))\n",
    "if show_figures:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=Warning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "if event_list is None:\n",
    "    index_list = charge_df.index\n",
    "else:\n",
    "    index_list = charge_df.index.intersection(event_list)\n",
    "\n",
    "light_indices = light_df[\"event\"].copy()\n",
    "\n",
    "for i, idx in enumerate(tqdm(index_list)):\n",
    "    charge_values = pd.DataFrame(\n",
    "        charge_df.loc[\n",
    "            idx,\n",
    "            [\n",
    "                \"event_hits_channelid\",\n",
    "                \"event_hits_x\",\n",
    "                \"event_hits_y\",\n",
    "                \"event_hits_z\",\n",
    "                \"event_hits_ts\",\n",
    "                \"event_hits_q\",\n",
    "            ],\n",
    "        ].to_list(),\n",
    "        index=[\"ch\", \"x\", \"y\", \"z\", \"t\", \"q\"],\n",
    "    ).T\n",
    "\n",
    "    non_zero_mask = (charge_values[\"ch\"] != 0) * (\n",
    "        charge_values[\"y\"] != 0\n",
    "    )  # Remove (0,0) entries\n",
    "    noisy_channels_mask = ~charge_values[\"ch\"].isin(\n",
    "        [ch[0] for ch in channel_disable_list]\n",
    "    )  # Disable channel 7\n",
    "    mask = non_zero_mask * noisy_channels_mask  # Full hits mask\n",
    "\n",
    "    # Apply boolean indexing to x, y, and z arrays\n",
    "    charge_values = charge_values[mask]\n",
    "    charge_values[\"q\"] = charge_values[\"q\"] * charge_gain  # Convert mV to ke\n",
    "\n",
    "    # temp = index_list[i + 1] if i + 1 < len(index_list) else index_list[0]\n",
    "    # light_event = match_dict.get(temp, [temp])[0]\n",
    "    light_event = match_dict.get(idx, [idx])[0]\n",
    "    light_matches = light_indices[light_indices == light_event].index\n",
    "    # light_indices = light_indices[light_indices != light_event]\n",
    "    light_values = light_df.loc[light_matches].dropna(subset=light_variable)\n",
    "\n",
    "    if len(charge_values) > 2:\n",
    "        if idx in individual_plots:\n",
    "            metrics[idx] = event_display(\n",
    "                idx,\n",
    "                charge_values,\n",
    "                light_values,\n",
    "                plot_cyl=False,\n",
    "            )\n",
    "            if show_figures:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "        else:\n",
    "            # Create a design matrix\n",
    "            labels = cluster_hits(charge_values[[\"x\", \"y\", \"z\"]].to_numpy())\n",
    "            # Fit clusters\n",
    "            metrics[idx] = fit_hit_clusters(\n",
    "                charge_values[[\"x\", \"y\", \"z\"]].to_numpy(),\n",
    "                charge_values[\"q\"].to_numpy(),\n",
    "                labels,\n",
    "            )\n",
    "\n",
    "        # Light to track geometry metrics\n",
    "        track_lines = []\n",
    "        for track_idx, values in metrics[idx].items():\n",
    "            if \"Fit_line\" not in values:\n",
    "                continue\n",
    "            values[\"SiPM\"] = light_geometry(\n",
    "                track_line=values[\"Fit_line\"],\n",
    "                track_norm=values[\"Fit_norm\"],\n",
    "                sipm_df=light_values,\n",
    "                light_variable=light_variable,\n",
    "            )\n",
    "            track_lines.append(values[\"Fit_line\"])\n",
    "\n",
    "        # Light and charge voxelization and fitting\n",
    "        metrics[idx][\"SiPM\"] = voxelize_hits(\n",
    "            charge_values,\n",
    "            light_values,\n",
    "            light_variable,\n",
    "            charge_lines=track_lines,\n",
    "        )\n",
    "\n",
    "        metrics[idx][\n",
    "            \"Pixel_mask\"\n",
    "        ] = mask.to_numpy()  # Save masks to original dataframe for reference\n",
    "        metrics[idx][\"Total_light\"] = light_values[light_variable].sum()\n",
    "        metrics[idx][\"Total_charge\"] = charge_values[\"q\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the warning filter (optional)\n",
    "warnings.filterwarnings(\"default\", category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics to a pickle file\n",
    "metrics_file = f\"{file_label}/metrics_{file_label}.pkl\"\n",
    "if overwrite_metrics or not os.path.isfile(metrics_file):\n",
    "    with open(metrics_file, \"wb\") as f:\n",
    "        pickle.dump(metrics, f)\n",
    "\n",
    "    print(f\"Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
