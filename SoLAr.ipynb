{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "\n",
    "import awkward as ak\n",
    "import latexify\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import uproot\n",
    "from itables import init_notebook_mode\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.ticker import AutoMinorLocator, MaxNLocator\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from skimage.measure import LineModelND, ransac\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from skspatial.objects import Cylinder, Line, Point, Triangle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "file_label = \"20230706_191437\"  # label for files generated by this notebook\n",
    "light_file = \"../Data/rwf_0cd913fa_20230706_191437.data_deco_2.root\"\n",
    "charge_file = \"../Data/evd_self_trigger-packets-2023_07_06_19_14_CEST_validated.root\"\n",
    "sipm_map_file = \"sipm_sn_ch_to_xy.json\"\n",
    "\n",
    "# Load options\n",
    "reload_file = False\n",
    "rematch_events = False\n",
    "\n",
    "# Plotting options\n",
    "individual_plots = []  # np.arange(1, 21, 1)\n",
    "show_figures = True\n",
    "\n",
    "# Events to process\n",
    "event_list = None\n",
    "# event_list = np.array([30, 50])\n",
    "# event_list = np.arange(0, 20, 1)\n",
    "\n",
    "# Noisy Pixels\n",
    "channel_disable_list = [7]\n",
    "\n",
    "# Light variable to consider\n",
    "light_variable = \"integral\"\n",
    "\n",
    "# Units for plot labels\n",
    "q_unit = \"ke\"  # After applying charge_gain\n",
    "xy_unit = \"mm\"\n",
    "z_unit = \"mm\"\n",
    "dh_unit = \"?\" if z_unit != xy_unit else xy_unit\n",
    "time_unit = \"ns\"\n",
    "light_unit = \"p.e.\" if light_variable == \"integral\" else \"p.e./time bin\"\n",
    "\n",
    "# Conversion factors\n",
    "charge_gain = 245  # mV to ke\n",
    "detector_z = 300\n",
    "detector_x = 128\n",
    "detector_y = 160\n",
    "\n",
    "# DBSCAN parameters for clustering\n",
    "min_samples = 2\n",
    "xy_epsilon = 8  # 8 ideal\n",
    "z_epsilon = 8  # 8 ideal\n",
    "\n",
    "# RANSAC parameters for line fitting\n",
    "residual_threshold = 6  # 6 ideal\n",
    "max_trials = 1000\n",
    "\n",
    "# Force parameters for cylinder\n",
    "force_dh = None\n",
    "force_dr = None\n",
    "\n",
    "# Filters for post processing\n",
    "p_value_limit = 0.05\n",
    "min_track_length = 160\n",
    "max_tracks = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SiPMs mapping\n",
    "sipm_map = None\n",
    "\n",
    "\n",
    "def sipm_to_xy(sn, ch):\n",
    "    global sipm_map\n",
    "    if sipm_map is None:\n",
    "        with open(sipm_map_file, \"r\") as f:\n",
    "            sipm_map = json.load(f)\n",
    "\n",
    "    xy = sipm_map.get(str(sn), {}).get(str(ch), None)\n",
    "    if xy is None:\n",
    "        return None\n",
    "    else:\n",
    "        x = xy[0] + 64\n",
    "        y = xy[1] - 16\n",
    "        return (x, y)\n",
    "\n",
    "\n",
    "# Check if SiPMs on anode area\n",
    "def get_sipm_mask(sn, ch):\n",
    "    xy = sipm_to_xy(sn, ch)\n",
    "    # return True\n",
    "    if xy is None:\n",
    "        return False\n",
    "    else:\n",
    "        return (\n",
    "            xy[0] > -detector_x / 2\n",
    "            and xy[0] < detector_x / 2\n",
    "            and xy[1] < detector_y / 2\n",
    "            and xy[1] > -detector_y / 2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cylinder parameters for dQ/dx\n",
    "def get_dh(unit_vector):\n",
    "    if force_dh is not None:\n",
    "        return force_dh\n",
    "\n",
    "    dl_vector = np.array([xy_epsilon, xy_epsilon, z_epsilon])\n",
    "    min_dh = np.linalg.norm(dl_vector) / 4\n",
    "    max_dh = 2 * np.linalg.norm(dl_vector)\n",
    "    dl_projection = abs(np.dot(unit_vector, dl_vector))\n",
    "    dh = min(max(dl_projection, min_dh), max_dh)\n",
    "\n",
    "    return dh\n",
    "\n",
    "\n",
    "def get_dr(standard_deviation):\n",
    "    if force_dr is not None:\n",
    "        return force_dr\n",
    "\n",
    "    dl_vector = np.array([xy_epsilon, xy_epsilon, z_epsilon])\n",
    "    min_dr = np.linalg.norm(dl_vector) / 4\n",
    "    dr = max(standard_deviation, min_dr)\n",
    "\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uproot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uproot\n",
    "def load_charge(file_name, events=None):\n",
    "    with uproot.open(file_name) as f:\n",
    "        charge_df = f[\"events\"].arrays(library=\"pd\").set_index(\"eventID\")\n",
    "        if events is not None:\n",
    "            charge_df = charge_df.loc[events]\n",
    "\n",
    "    return charge_df\n",
    "\n",
    "\n",
    "def load_light(file_name, deco=True, events=None, mask=True, keep_rwf=False):\n",
    "    light_df = pd.DataFrame()\n",
    "    with uproot.open(file_name) as f:\n",
    "        if deco:\n",
    "            tree = f[\"decowave\"]\n",
    "        else:\n",
    "            tree = f[\"rwf_array\"]\n",
    "\n",
    "        for idx, arrays in enumerate(tree.iterate(library=\"np\")):\n",
    "            df = pd.DataFrame.from_dict(arrays, orient=\"index\").T\n",
    "            df.dropna()\n",
    "            if events is not None:\n",
    "                df = df[df[\"event\"].isin(events)]\n",
    "\n",
    "            if mask:\n",
    "                df = df[\n",
    "                    df[[\"sn\", \"ch\"]].apply(lambda x: get_sipm_mask(x[0], x[1]), axis=1)\n",
    "                ]\n",
    "\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            df[[\"x\", \"y\"]] = df[[\"sn\", \"ch\"]].apply(\n",
    "                lambda x: pd.Series(sipm_to_xy(x[0], x[1])), axis=1\n",
    "            )\n",
    "\n",
    "            if deco:\n",
    "                df[\"rwf\"] = df[\"decwfm\"]\n",
    "\n",
    "            df[[\"integral\", \"properties\"]] = df[\"rwf\"].apply(\n",
    "                lambda x: pd.Series(\n",
    "                    (np.nan, {}) if any(np.isnan(x)) else integrate_peaks(x)\n",
    "                )\n",
    "            )\n",
    "            df[\"peak\"] = df[\"properties\"].apply(\n",
    "                lambda x: max(x[\"peak_heights\"])\n",
    "                if \"peak_heights\" in x and len(x[\"peak_heights\"]) > 0\n",
    "                else np.nan\n",
    "            )\n",
    "\n",
    "            columns = [\"event\", \"tai_ns\", \"sn\", \"ch\", \"peak\", \"integral\", \"x\", \"y\"]\n",
    "            if keep_rwf:\n",
    "                columns.append(\"rwf\")\n",
    "\n",
    "            df = df[columns]\n",
    "            light_df = pd.concat([light_df, df], ignore_index=True)\n",
    "\n",
    "    return light_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metrics(metrics, p_value_limit=0.05, min_track_length=160, max_tracks=1):\n",
    "    filtered_metrics = {}\n",
    "    non_track_keys = 4\n",
    "\n",
    "    for event_idx, metric in metrics.items():\n",
    "        if len(metric) == max_tracks + non_track_keys:\n",
    "            candidate_metric = {\n",
    "                track_idx: values\n",
    "                for track_idx, values in metric.items()\n",
    "                if isinstance(track_idx, str)\n",
    "                or (\n",
    "                    track_idx > 0\n",
    "                    and values[\"Fit_p_value\"] <= p_value_limit\n",
    "                    and values[\"Fit_norm\"] >= min_track_length\n",
    "                )\n",
    "            }\n",
    "            if len(candidate_metric) == max_tracks + non_track_keys:\n",
    "                filtered_metrics[event_idx] = candidate_metric\n",
    "\n",
    "    return filtered_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak finding algorithm for integration\n",
    "def integrate_peaks(waveform, buffer_size=10, height=0.1, prominence=0.05):\n",
    "    # Find peaks in the filtered waveform\n",
    "    peaks, properties = signal.find_peaks(\n",
    "        waveform, height=height, prominence=prominence\n",
    "    )\n",
    "\n",
    "    integration_result = 0\n",
    "    start_index = 0  # Initialize the start index\n",
    "    end_index = 0  # Initialize the end index\n",
    "\n",
    "    for peak in peaks:\n",
    "        # Determine the potential start and end indices\n",
    "        potential_start = max(0, peak - buffer_size)\n",
    "        potential_end = min(len(waveform), peak + buffer_size)\n",
    "\n",
    "        # If the potential start is within the current peak region, update the end index\n",
    "        if potential_start <= end_index:\n",
    "            end_index = potential_end\n",
    "        else:\n",
    "            # Integrate the previous peak region and update indices for the new peak\n",
    "            peak_region = waveform[start_index:end_index]\n",
    "            integration_result += np.trapz(peak_region)\n",
    "            start_index = potential_start\n",
    "            end_index = potential_end\n",
    "\n",
    "    # Integrate the last peak region\n",
    "    peak_region = waveform[start_index:end_index]\n",
    "    integration_result += np.trapz(peak_region)\n",
    "\n",
    "    return integration_result, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dict = {}\n",
    "\n",
    "\n",
    "def match_events(charge_df, light_df, window=10):\n",
    "    match_dict = {}\n",
    "\n",
    "    charge_events = charge_df[[\"event_unix_ts\", \"event_start_t\"]].drop_duplicates()\n",
    "    light_events = light_df[[\"tai_ns\", \"event\"]].drop_duplicates()\n",
    "\n",
    "    for event, row in tqdm(charge_events.iterrows(), total=len(charge_events)):\n",
    "        charge_ts = (float(row[\"event_unix_ts\"]) * 1e6) + (\n",
    "            float(row[\"event_start_t\"]) * 1e-1\n",
    "        )\n",
    "        light_matches = light_events.where(\n",
    "            abs(light_events[\"tai_ns\"].astype(float) * 1e-3 - 36000000 - charge_ts)\n",
    "            <= window\n",
    "        ).dropna()\n",
    "\n",
    "        if not light_matches.empty:\n",
    "            if event in match_dict:\n",
    "                match_dict[event].append(\n",
    "                    light_matches[\"event\"].unique().astype(int).tolist()\n",
    "                )\n",
    "            else:\n",
    "                match_dict[event] = light_matches[\"event\"].unique().astype(int).tolist()\n",
    "\n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of fake data\n",
    "def generate_dead_area(z_range):\n",
    "    # Dead area on chips 44, 54, detector_x/2\n",
    "    fake_x1, fake_y1, fake_z1 = np.meshgrid(\n",
    "        np.linspace(36, 60, 6),\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(-76, -52, 6),\n",
    "                np.linspace(-44, -20, 6),\n",
    "                np.linspace(-12, 12, 6),\n",
    "            ]\n",
    "        ),\n",
    "        z_range,\n",
    "    )\n",
    "\n",
    "    # Dead area on chip 33\n",
    "    fake_x2, fake_y2, fake_z2 = np.meshgrid(\n",
    "        np.linspace(4, 28, 6), np.linspace(20, 44, 6), z_range\n",
    "    )\n",
    "\n",
    "    # Dead area on chip 42\n",
    "    fake_x3, fake_y3, fake_z3 = np.meshgrid(\n",
    "        np.linspace(-28, -4, 6), np.linspace(-12, 12, 6), z_range\n",
    "    )\n",
    "    mask = fake_x3 + (fake_y3 + 16) <= 0\n",
    "    fake_x3, fake_y3, fake_z3 = fake_x3[mask], fake_y3[mask], fake_z3[mask]\n",
    "\n",
    "    fake_x4, fake_y4, fake_z4 = np.meshgrid([-14], [2], z_range)\n",
    "\n",
    "    # Dead area on SiPMs\n",
    "    fake_x5 = []\n",
    "    fake_y5 = []\n",
    "    fake_z5 = []\n",
    "    for k in range(4):\n",
    "        for l in range(5):\n",
    "            if (k == 3 and l < 3) or (k == 2 and l == 3) or (k == 1 and l == 2):\n",
    "                continue\n",
    "\n",
    "            temp_x, temp_y, temp_z = np.meshgrid(\n",
    "                np.array([-50, -46]) + 32 * k,\n",
    "                np.array([-66, -62]) + 32 * l,\n",
    "                z_range,\n",
    "            )\n",
    "\n",
    "            fake_x5.extend(temp_x)\n",
    "            fake_y5.extend(temp_y)\n",
    "            fake_z5.extend(temp_z)\n",
    "\n",
    "    fake_x5 = np.array(fake_x5)\n",
    "    fake_y5 = np.array(fake_y5)\n",
    "    fake_z5 = np.array(fake_z5)\n",
    "\n",
    "    # Concatenate all the fake data\n",
    "    fake_x = np.concatenate(\n",
    "        [\n",
    "            fake_x1.flatten(),\n",
    "            fake_x2.flatten(),\n",
    "            fake_x3.flatten(),\n",
    "            fake_x4.flatten(),\n",
    "            fake_x5.flatten(),\n",
    "        ]\n",
    "    )\n",
    "    fake_y = np.concatenate(\n",
    "        [\n",
    "            fake_y1.flatten(),\n",
    "            fake_y2.flatten(),\n",
    "            fake_y3.flatten(),\n",
    "            fake_y4.flatten(),\n",
    "            fake_y5.flatten(),\n",
    "        ]\n",
    "    )\n",
    "    fake_z = np.concatenate(\n",
    "        [\n",
    "            fake_z1.flatten(),\n",
    "            fake_z2.flatten(),\n",
    "            fake_z3.flatten(),\n",
    "            fake_z4.flatten(),\n",
    "            fake_z5.flatten(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fake_data = np.c_[fake_x, fake_y, fake_z]\n",
    "\n",
    "    return fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN clustering\n",
    "def cluster(hitArray):\n",
    "    # First stage clustering\n",
    "    z_intervals = []\n",
    "    first_stage = DBSCAN(eps=xy_epsilon, min_samples=min_samples).fit(hitArray[:, 0:2])\n",
    "    for label in first_stage.labels_:\n",
    "        if label > -1:\n",
    "            mask = first_stage.labels_ == label\n",
    "            z = hitArray[mask, 2]\n",
    "            z_intervals.append((min(z), max(z)))\n",
    "\n",
    "    # Sort the intervals based on their start points\n",
    "    sorted_intervals = sorted(z_intervals, key=lambda interval: interval[0])\n",
    "\n",
    "    # Initialize a list to store the intervals representing the empty space\n",
    "    empty_space_ranges = []\n",
    "\n",
    "    # Iterate through the sorted intervals to find the gaps\n",
    "    for i in range(len(sorted_intervals) - 1):\n",
    "        current_interval = sorted_intervals[i]\n",
    "        next_interval = sorted_intervals[i + 1]\n",
    "\n",
    "        # Calculate the gap between the current interval and the next interval\n",
    "        gap_start = current_interval[1]\n",
    "        gap_end = next_interval[0]\n",
    "\n",
    "        # Check if there is a gap (empty space) between intervals\n",
    "        if gap_end > gap_start and gap_end < gap_start + 40:\n",
    "            empty_space_ranges.append(np.arange(gap_start, gap_end, z_epsilon))\n",
    "\n",
    "    if not empty_space_ranges:\n",
    "        empty_space_ranges.append(\n",
    "            np.arange(\n",
    "                np.mean(hitArray[:, 2]) - np.std(hitArray[:, 2]),\n",
    "                np.mean(hitArray[:, 2]) + np.std(hitArray[:, 2]),\n",
    "                z_epsilon,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    z_range = np.concatenate(empty_space_ranges)\n",
    "\n",
    "    # Create a list of holes\n",
    "    fake_data = generate_dead_area(z_range)\n",
    "    fake_data_count = len(fake_data)\n",
    "\n",
    "    # Second stage clustering\n",
    "    # Combine fake to true data\n",
    "    second_stage_data = np.concatenate([hitArray, fake_data])\n",
    "    second_stage = DBSCAN(eps=xy_epsilon, min_samples=1).fit(second_stage_data[:, 0:2])\n",
    "\n",
    "    # Third stage clustering\n",
    "    # Create a new array with z and labels\n",
    "    third_stage_z = np.c_[second_stage.labels_ * 1e3, second_stage_data[:, 2]]\n",
    "    flag = second_stage.labels_ > -1\n",
    "    third_stage_data = third_stage_z[flag].copy()\n",
    "    third_stage = DBSCAN(\n",
    "        eps=z_epsilon, min_samples=min_samples, metric=\"chebyshev\"\n",
    "    ).fit(third_stage_data)\n",
    "\n",
    "    # Remove fake data\n",
    "    # Shift labels by 1 so that negative values are reserved for outliers\n",
    "    labels = third_stage.labels_[:-fake_data_count] + 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "# Apply Ransac Fit\n",
    "def ransacFit(hitArray, weightArray=None):\n",
    "    if weightArray is not None:\n",
    "        estimator = RANSACRegressor(\n",
    "            min_samples=min_samples,\n",
    "            max_trials=max_trials,\n",
    "            residual_threshold=residual_threshold,\n",
    "        )\n",
    "        inliers = estimator.fit(\n",
    "            hitArray[:, 0:2],\n",
    "            hitArray[:, 2],\n",
    "            sample_weight=weightArray,\n",
    "        ).inlier_mask_\n",
    "\n",
    "        score = estimator.score(hitArray[:, 0:2], hitArray[:, 2])\n",
    "    else:\n",
    "        model_robust, inliers = ransac(\n",
    "            hitArray,\n",
    "            LineModelND,\n",
    "            min_samples=min_samples,\n",
    "            residual_threshold=residual_threshold,\n",
    "            max_trials=max_trials,\n",
    "        )\n",
    "\n",
    "        score = model_robust.score(hitArray)\n",
    "\n",
    "    outliers = inliers == False\n",
    "    return inliers, outliers, score\n",
    "\n",
    "\n",
    "# Apply best line fit\n",
    "def lineFit(hitArray):\n",
    "    line = Line.best_fit(hitArray)\n",
    "    residuals = []\n",
    "    for point in hitArray:\n",
    "        distance = line.distance_point(point)\n",
    "        residuals.append(distance)\n",
    "\n",
    "    # Convert residuals to a numpy array\n",
    "    residuals = np.array(residuals)\n",
    "\n",
    "    # Calculate chi-squared\n",
    "    chi_squared = np.sum(residuals**2)\n",
    "\n",
    "    return line, chi_squared\n",
    "\n",
    "\n",
    "# Calculate dQ/dx from a line fit\n",
    "def dqdx(hitArray, q, line_fit, dh, dr, h, ax=None):\n",
    "    # Cylinder steps for dQ/dx\n",
    "    steps = np.arange(-3 * dh, h + 2 * dh, dh)\n",
    "\n",
    "    # Mask of points that have been accounted for\n",
    "    counted = np.zeros(len(q), dtype=bool)\n",
    "\n",
    "    # Array of dQ values for each step\n",
    "    dq_i = np.zeros(len(steps), dtype=float)\n",
    "\n",
    "    for step_idx, step in enumerate(steps):\n",
    "        cylinder_fit = Cylinder(\n",
    "            line_fit.to_point(h / 2 - step),\n",
    "            -line_fit.direction.unit() * dh,\n",
    "            dr,\n",
    "        )\n",
    "        if ax is not None:\n",
    "            cylinder_fit.plot_3d(ax)\n",
    "\n",
    "        for point_idx, point in enumerate(hitArray):\n",
    "            if not counted[point_idx] and cylinder_fit.is_point_within(point):\n",
    "                counted[point_idx] = True\n",
    "                dq_i[step_idx] += q[point_idx]\n",
    "\n",
    "    return dq_i\n",
    "\n",
    "\n",
    "# Fit clusters with Ransac method\n",
    "def fitClusters(\n",
    "    hitArray, q, labels, ax2d=None, ax3d=None, plot_cyl=False, refit_outliers=True\n",
    "):\n",
    "    metrics = {}\n",
    "    # Fit clusters\n",
    "    idx = 0\n",
    "    condition = lambda: idx < len(np.unique(labels))\n",
    "    while condition():\n",
    "        label = np.unique(labels)[idx]\n",
    "        mask = labels == label\n",
    "        if label > 0 and mask.sum() > min_samples:\n",
    "            xyz_c = hitArray[mask]\n",
    "            x_c, y_c, z_c = xyz_c[:, 0], xyz_c[:, 1], xyz_c[:, 2]\n",
    "            q_c = np.array(q)[mask]\n",
    "\n",
    "            norm = np.linalg.norm(\n",
    "                [\n",
    "                    x_c.max() - x_c.min(),\n",
    "                    y_c.max() - y_c.min(),\n",
    "                    z_c.max() - z_c.min(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Fit the model\n",
    "            inliers, outliers, score = ransacFit(xyz_c, q_c - min(q_c) + 1)\n",
    "\n",
    "            # Refit outliers\n",
    "            level_1 = np.where(mask)[0]\n",
    "            level_2 = np.where(outliers)[0]\n",
    "            level_3 = level_1[level_2]\n",
    "\n",
    "            if refit_outliers and sum(outliers) > min_samples:\n",
    "                outlier_labels = cluster(xyz_c[outliers])\n",
    "                last_label = max(labels) + 1\n",
    "                # Assign positive labels to clustered outliers and negative labels to unlclustered outliers\n",
    "                for i, j in enumerate(level_3):\n",
    "                    labels[j] = (outlier_labels[i] + last_label) * (\n",
    "                        1 if outlier_labels[i] > 0 else -1\n",
    "                    )\n",
    "            else:\n",
    "                # Assign negative labels to outliers\n",
    "                for j in level_3:\n",
    "                    labels[j] = -labels[j]\n",
    "\n",
    "            if sum(inliers) > min_samples:\n",
    "                line_fit, chi_squared = lineFit(xyz_c[inliers])\n",
    "                # Degrees of freedom (number of points - number of parameters in the line fit)\n",
    "                degrees_of_freedom = sum(inliers) - 1\n",
    "                # Calculate the reduced chi squared\n",
    "                reduced_chi_squared = chi_squared / degrees_of_freedom\n",
    "                # Calculate the p-value (assuming chi-squared distribution)\n",
    "                p_value = 1 - stats.chi2.cdf(chi_squared, degrees_of_freedom)\n",
    "\n",
    "                if ax2d is not None:\n",
    "                    # 2D plot\n",
    "                    line_fit.plot_2d(\n",
    "                        ax2d,\n",
    "                        t_1=-norm / 2,\n",
    "                        t_2=norm / 2,\n",
    "                        c=\"red\",\n",
    "                        label=f\"Track {label}\",\n",
    "                        zorder=10,\n",
    "                    )\n",
    "                if ax3d is not None:\n",
    "                    # 3D plot\n",
    "                    line_fit.plot_3d(\n",
    "                        ax3d,\n",
    "                        t_1=-norm / 2,\n",
    "                        t_2=norm / 2,\n",
    "                        c=\"red\",\n",
    "                        label=f\"Track {label}\",\n",
    "                    )\n",
    "\n",
    "                # Calculate dQ/dx\n",
    "                dh = get_dh(line_fit.direction)\n",
    "                dr = get_dr(np.sqrt(reduced_chi_squared))\n",
    "\n",
    "                dq_i = dqdx(\n",
    "                    xyz_c[inliers],\n",
    "                    q_c[inliers],\n",
    "                    line_fit,\n",
    "                    dh=dh,\n",
    "                    dr=dr,\n",
    "                    h=norm,\n",
    "                    ax=ax3d if ax3d is not None and plot_cyl else None,\n",
    "                )\n",
    "\n",
    "                q_eff = dq_i.sum() / q_c[inliers].sum()\n",
    "                if dq_i.sum() != 0:\n",
    "                    dq = dq_i\n",
    "                else:\n",
    "                    dq = 0\n",
    "\n",
    "                metrics[label] = {\n",
    "                    \"Fit_line\": line_fit,\n",
    "                    \"Fit_norm\": norm,\n",
    "                    \"Fit_p_value\": p_value,\n",
    "                    \"RANSAC_score\": score,\n",
    "                    \"q_eff\": q_eff,\n",
    "                    \"dQ\": dq,\n",
    "                    \"dx\": dh,\n",
    "                }\n",
    "\n",
    "        idx = np.unique(labels).tolist().index(label) + 1\n",
    "\n",
    "    metrics[\"Fit_labels\"] = labels\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_std(array, ax, array_max=1000, min_count_ratio=0.99, max_std_ratio=0.5):\n",
    "    max_std = array.std()\n",
    "    max_count = len(array)\n",
    "\n",
    "    std = []\n",
    "    count = []\n",
    "    x_range = range(1, (array_max + 1), 1)\n",
    "    for i in x_range:\n",
    "        cut = array[(array < i)]\n",
    "        std.append(cut.std())\n",
    "        count.append(len(cut))\n",
    "\n",
    "    std = np.array(std)\n",
    "    count = np.array(count)\n",
    "    condition = (count / max_count > min_count_ratio) & (std / max_std < max_std_ratio)\n",
    "    vline = x_range[\n",
    "        np.where(condition)[0][-1]\n",
    "        if np.any(condition)\n",
    "        else (count / max_count > min_count_ratio).argmax()\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        \"Max STD ratio\",\n",
    "        max_std_ratio,\n",
    "        \"limited to\",\n",
    "        min_count_ratio * 100,\n",
    "        \"% of events:\",\n",
    "        vline,\n",
    "    )\n",
    "\n",
    "    ax.plot(std / max_std, label=\"STD ratio\")\n",
    "    ax.plot(count / max_count, label=\"Event count ratio\")\n",
    "    ax.axvline(vline, ls=\"--\", c=\"r\", label=f\"{min_count_ratio*100}% of events\")\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "    return vline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_geometry(track_line, track_norm, sipm_df, light_variable=\"integral\"):\n",
    "    metrics = {\"Light_distance\": {}, \"Light_angle\": {}, f\"Light_{light_variable}\": {}}\n",
    "    point1 = track_line.to_point(-track_norm / 2)\n",
    "    point2 = track_line.to_point(track_norm / 2)\n",
    "    centre = track_line.point\n",
    "\n",
    "    iterate_df = sipm_df.dropna(subset=light_variable).copy()\n",
    "    for row, sipm in iterate_df.iterrows():\n",
    "        sipm_idx = (sipm[\"sn\"], sipm[\"ch\"])\n",
    "        point3 = Point([sipm[\"x\"], sipm[\"y\"], 0])\n",
    "        triangle = Triangle(point1, point2, point3)\n",
    "        angle = triangle.angle(\"C\")\n",
    "        distance = point3.distance_point(centre)\n",
    "        metrics[\"Light_distance\"][sipm_idx] = distance\n",
    "        metrics[\"Light_angle\"][sipm_idx] = angle\n",
    "        metrics[f\"Light_{light_variable}\"][sipm_idx] = sipm[light_variable]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_axes(event_idx, charge, light):\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    ax3d = fig.add_subplot(121, projection=\"3d\")\n",
    "    ax2d = fig.add_subplot(122)\n",
    "    fig.suptitle(\n",
    "        f\"Event {event_idx} - Charge = {charge} {q_unit} - Light = {light} {light_unit}\"\n",
    "    )\n",
    "    grid_color = plt.rcParams[\"grid.color\"]\n",
    "\n",
    "    # Draw dead areas\n",
    "    for i in range(4):\n",
    "        j = 0\n",
    "        if i == 3:\n",
    "            j = 1\n",
    "        ax2d.plot(\n",
    "            np.arange(32, 64 + 1, 1) - 32 * j,\n",
    "            np.arange(-80, -48 + 1, 1) + 32 * i,\n",
    "            c=grid_color,\n",
    "            lw=1,\n",
    "        )\n",
    "        ax2d.plot(\n",
    "            np.arange(64, 32 - 1, -1) - 32 * j,\n",
    "            np.arange(-80, -48 + 1, 1) + 32 * i,\n",
    "            c=grid_color,\n",
    "            lw=1,\n",
    "        )\n",
    "\n",
    "    # ax2d.plot(np.linspace(-31,0),np.linspace(8,-16), c=grid_color,lw = 1)\n",
    "    ax2d.plot(np.linspace(-32, 0), np.linspace(16, -16), c=grid_color, lw=1, zorder=-1)\n",
    "    ax2d.plot(np.linspace(-32, -16), np.linspace(-16, 0), c=grid_color, lw=1, zorder=-1)\n",
    "\n",
    "    # Adjust axes\n",
    "    for ax in [ax3d, ax2d]:\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        ax.set_xlim([-detector_x / 2, detector_x / 2])\n",
    "        ax.set_ylim([-detector_y / 2, detector_y / 2])\n",
    "        ax.set_xlabel(f\"x [{xy_unit}]\")\n",
    "        ax.set_ylabel(f\"y [{xy_unit}]\")\n",
    "        ax.set_xticks(np.linspace(-detector_x / 2, detector_x / 2, 5))\n",
    "        ax.set_yticks(np.linspace(-detector_y / 2, detector_y / 2, 6))\n",
    "        ax.grid()\n",
    "\n",
    "    ax2d.xaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax2d.yaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax2d.tick_params(axis=\"both\", which=\"both\", right=True, top=True)\n",
    "\n",
    "    # Adjust z-axis\n",
    "    ax3d.set_zlabel(f\"z [{z_unit}]\")\n",
    "    # ax3d.zaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    return fig, (ax2d, ax3d)\n",
    "\n",
    "\n",
    "def event_display(\n",
    "    event_idx,\n",
    "    charge_x_array,\n",
    "    charge_y_array,\n",
    "    charge_z_array,\n",
    "    charge_time_array,\n",
    "    charge_array,\n",
    "    light_x_array=[],\n",
    "    light_y_array=[],\n",
    "    light_array=[],\n",
    "    plot_cyl=False,\n",
    "):\n",
    "    if len(charge_x_array) < 2:\n",
    "        return None\n",
    "\n",
    "    # Plot the hits\n",
    "    fig, axes = create_axes(\n",
    "        event_idx, round(sum(charge_array)), round(sum(light_array))\n",
    "    )\n",
    "    ax2d = axes[0]\n",
    "    ax3d = axes[1]\n",
    "\n",
    "    # Group by x and y coordinates and sum the z values\n",
    "    data2d = np.c_[charge_x_array, charge_y_array, charge_array]\n",
    "    unique_points, indices = np.unique(data2d[:, :2], axis=0, return_inverse=True)\n",
    "    q_sum = np.bincount(indices, weights=data2d[:, 2])\n",
    "\n",
    "    # Plot the hits\n",
    "    plot3d = ax3d.scatter(\n",
    "        charge_x_array,\n",
    "        charge_y_array,\n",
    "        charge_z_array,\n",
    "        c=charge_array,\n",
    "        marker=\"s\",\n",
    "        s=30,\n",
    "        vmin=q_sum.min(),\n",
    "        vmax=q_sum.max(),\n",
    "    )\n",
    "    plot2d = ax2d.scatter(\n",
    "        unique_points[:, 0],\n",
    "        unique_points[:, 1],\n",
    "        c=q_sum,\n",
    "        marker=\"s\",\n",
    "        s=40,\n",
    "        vmin=q_sum.min(),\n",
    "        vmax=q_sum.max(),\n",
    "    )\n",
    "    cbar = plt.colorbar(plot2d)\n",
    "    cbar.set_label(f\"charge [{q_unit}]\")\n",
    "\n",
    "    # Create a design matrix\n",
    "    xyz = np.c_[charge_x_array, charge_y_array, charge_z_array]\n",
    "\n",
    "    # Cluster the hits\n",
    "    labels = cluster(xyz)\n",
    "\n",
    "    # Fit clusters\n",
    "    metrics = fitClusters(xyz, charge_array, labels, ax2d, ax3d, plot_cyl)\n",
    "\n",
    "    # Draw missing SiPMs\n",
    "    grid_color = plt.rcParams[\"grid.color\"]\n",
    "\n",
    "    # Draw SiPMs\n",
    "    sipm_plot = ax2d.scatter(\n",
    "        light_x_array,\n",
    "        light_y_array,\n",
    "        c=light_array,\n",
    "        marker=\"s\",\n",
    "        s=200,\n",
    "        linewidths=1.5,\n",
    "        edgecolors=grid_color,\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "    # Draw SiPMs\n",
    "    side_size = 6\n",
    "    vertices_x = np.array([1, 1, -1, -1, 1]) * side_size / 2\n",
    "    vertices_y = np.array([1, -1, -1, 1, 1]) * side_size / 2\n",
    "    light_xy = list(zip(light_x_array, light_y_array))\n",
    "    for missing_index in range(20):\n",
    "        col = -48 + (missing_index % 4) * 32\n",
    "        row = 64 - (missing_index // 4) * 32\n",
    "        square = create_square((col, row), side_size)\n",
    "        if (col, row) not in light_xy:\n",
    "            ax2d.fill(col + vertices_x, vertices_y + row, c=grid_color, zorder=5)\n",
    "            ax3d.add_collection3d(Poly3DCollection(square, color=grid_color))\n",
    "        else:\n",
    "            ax3d.add_collection3d(\n",
    "                Poly3DCollection(\n",
    "                    square,\n",
    "                    facecolors=sipm_plot.to_rgba(\n",
    "                        light_array.iloc[light_xy.index((col, row))]\n",
    "                    ),\n",
    "                    linewidths=0.5,\n",
    "                    edgecolors=grid_color,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    sipm_cbar = plt.colorbar(sipm_plot)\n",
    "    sipm_cbar.set_label(rf\"Light {light_variable} [{light_unit}]\")\n",
    "\n",
    "    # ax2d.legend()\n",
    "    # ax3d.legend()\n",
    "    ax3d.set_zlim([0, ax3d.get_zlim()[1]])\n",
    "    # ax3d.view_init(160, 110, -85)\n",
    "    ax3d.view_init(30, 20, 100)\n",
    "    # ax3d.view_init(0, 0, 0)\n",
    "    # ax3d.view_init(0, 0, 90)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(f\"event_{event_idx}.png\", dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a square based on center coordinates and side size\n",
    "def create_square(center, side_size):\n",
    "    x = [\n",
    "        center[0] - side_size / 2,\n",
    "        center[0] + side_size / 2,\n",
    "        center[0] + side_size / 2,\n",
    "        center[0] - side_size / 2,\n",
    "        center[0] - side_size / 2,\n",
    "    ]\n",
    "    y = [\n",
    "        center[1] - side_size / 2,\n",
    "        center[1] - side_size / 2,\n",
    "        center[1] + side_size / 2,\n",
    "        center[1] + side_size / 2,\n",
    "        center[1] - side_size / 2,\n",
    "    ]\n",
    "    z = [0, 0, 0, 0, 0]  # All z-coordinates are set to 0 to align with the xy-plane\n",
    "\n",
    "    vertices = [(x[i], y[i], z[i]) for i in range(5)]\n",
    "    square = [[vertices[0], vertices[1], vertices[2], vertices[3]]]\n",
    "    return square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dQ versus X\n",
    "def plot_dQ(dQ_array, event_idx, track_idx, dh, interpolate=False):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax_twinx = ax.twinx()\n",
    "\n",
    "    fig.suptitle(\n",
    "        rf\"Event {event_idx} - Track {track_idx} - $dx = {round(dh,2)}$ {dh_unit}\"\n",
    "    )\n",
    "\n",
    "    mean_dQ = np.mean(dQ_array[dQ_array > 0])\n",
    "    non_zero_indices = np.where(dQ_array > 0)[0]\n",
    "\n",
    "    # Check if there are non-zero values in dQ_array\n",
    "    if non_zero_indices.size > 0:\n",
    "        # Find the first non-zero index and add 2 indices before it\n",
    "        first_index = max(non_zero_indices[0] - 2, 0)\n",
    "\n",
    "        # Find the last non-zero index and add 2 indices after it\n",
    "        last_index = min(non_zero_indices[-1] + 2, len(dQ_array))\n",
    "\n",
    "        new_dQ_array = dQ_array.copy()[first_index:last_index]\n",
    "\n",
    "        if interpolate:\n",
    "            new_dQ_array[1:-1] = np.where(\n",
    "                new_dQ_array[1:-1] == 0,\n",
    "                mean_dQ,\n",
    "                new_dQ_array[1:-1],\n",
    "            )\n",
    "\n",
    "        dQ_array = new_dQ_array\n",
    "\n",
    "    ax.axhline(\n",
    "        mean_dQ / dh,\n",
    "        ls=\"--\",\n",
    "        c=\"red\",\n",
    "        label=rf\"Mean = ${round(mean_dQ/dh,2)}$ {q_unit} {dh_unit}$^{{-1}}$\",\n",
    "        lw=1,\n",
    "    )\n",
    "    x_range = np.arange(0, len(dQ_array) * dh, dh)[: len(dQ_array)]\n",
    "\n",
    "    ax.step(x_range, dQ_array / dh, where=\"mid\")\n",
    "    ax.set_xlabel(rf\"$x$ [{dh_unit}]\")\n",
    "    ax.set_ylabel(rf\"$dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "\n",
    "    ax_twinx.step(x_range, np.cumsum(dQ_array), color=\"C1\", where=\"mid\")\n",
    "    ax_twinx.set_ylabel(f\"Q [{q_unit}]\")\n",
    "\n",
    "    for axes in [ax, ax_twinx]:\n",
    "        axes.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axes.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        axes.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        axes.tick_params(axis=\"both\", direction=\"inout\", which=\"major\", top=True)\n",
    "\n",
    "    h1, l1 = ax.get_legend_handles_labels()\n",
    "    ax_twinx.legend(h1, l1, loc=\"lower center\")\n",
    "\n",
    "    ax.legend(loc=\"lower center\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"dQ_{event_idx}_{track_idx}_{round(dh,2)}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_track_stats(\n",
    "    metrics,\n",
    "    limit_xrange=True,\n",
    "    p_value_limit=0.05,\n",
    "    empty_ratio_lims=(0, 1),\n",
    "    min_entries=2,\n",
    "    lognorm=True,\n",
    "    bins=[40, 40],\n",
    "):\n",
    "    track_mean_dQdx = []\n",
    "    track_std_dQdx = []\n",
    "    track_length = []\n",
    "    track_p_value = []\n",
    "    dQdx_list = []\n",
    "\n",
    "    empty_count = 0\n",
    "    short_count = 0\n",
    "    for entry in metrics.values():\n",
    "        for track, values in entry.items():\n",
    "            if isinstance(track, str) or track <= 0:\n",
    "                continue\n",
    "\n",
    "            dQ = values[\"dQ\"]\n",
    "            dx = values[\"dx\"]\n",
    "            non_zero_mask = np.where(dQ > 0)[0]\n",
    "\n",
    "            if len(dQ[non_zero_mask]) < min_entries:\n",
    "                short_count += 1\n",
    "                continue\n",
    "\n",
    "            empty_ratio = sum(dQ[non_zero_mask[0] : non_zero_mask[-1] + 1] == 0) / (\n",
    "                non_zero_mask[-1] - non_zero_mask[0] + 1\n",
    "            )\n",
    "\n",
    "            if empty_ratio > empty_ratio_lims[1] or empty_ratio < empty_ratio_lims[0]:\n",
    "                empty_count += 1\n",
    "                continue\n",
    "\n",
    "            dQdx = dQ[non_zero_mask[0] : non_zero_mask[-1] + 1] / dx\n",
    "            x_range = np.arange(0, len(dQdx) * dx, dx)[: len(dQdx)]\n",
    "            dQdx_list.append(pd.Series(dQdx, index=x_range))\n",
    "\n",
    "            non_zero_mask = non_zero_mask[non_zero_mask[0] : non_zero_mask[-1] + 1]\n",
    "            track_mean_dQdx.append(np.mean(dQdx[dQdx > 0]))\n",
    "            track_std_dQdx.append(np.std(dQdx[dQdx > 0]))\n",
    "            track_length.append(values[\"Fit_norm\"])\n",
    "            track_p_value.append(values[\"Fit_p_value\"])\n",
    "\n",
    "    print(f\"Tracks with dead area outside {empty_ratio_lims} interval: {empty_count}\")\n",
    "    print(f\"Tracks with less than {min_entries} entries: {short_count}\")\n",
    "\n",
    "    print(len(track_mean_dQdx))\n",
    "    track_mean_dQdx = pd.Series(track_mean_dQdx)\n",
    "    track_std_dQdx = pd.Series(track_std_dQdx)\n",
    "    track_length = pd.Series(track_length)\n",
    "    track_p_value = pd.Series(track_p_value)\n",
    "    mask = track_mean_dQdx.notna() * track_length.notna() * track_p_value.notna()\n",
    "\n",
    "    print(f\"Remaining tracks: {sum(mask)}\")\n",
    "\n",
    "    track_mean_dQdx = track_mean_dQdx[mask]\n",
    "    track_std_dQdx = track_std_dQdx[mask]\n",
    "    track_length = track_length[mask]\n",
    "    track_p_value = track_p_value[mask]\n",
    "    track_cv_dQdx = track_std_dQdx / track_mean_dQdx\n",
    "\n",
    "    p_mask = track_p_value <= p_value_limit\n",
    "    p_bool = (1 - p_mask).sum() > 0\n",
    "\n",
    "    print(f\"Tracks with p_value > {p_value_limit}: {sum(mask)-sum(p_mask)}\")\n",
    "\n",
    "    print(f\"Remaining_tracks: {sum(p_mask)}\")\n",
    "\n",
    "    # 1D histograms\n",
    "    fig1 = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    ax11 = fig1.add_subplot(121)\n",
    "    ax12 = fig1.add_subplot(122)\n",
    "\n",
    "    n_all11, bins_all11, patches_all11 = ax11.hist(\n",
    "        track_mean_dQdx, bins=bins[0], label=\"All tracks\"\n",
    "    )\n",
    "\n",
    "    n_all12, bins_all12, patches_all12 = ax12.hist(\n",
    "        track_length, bins=bins[0], label=\"All tracks\"\n",
    "    )\n",
    "\n",
    "    if p_bool:\n",
    "        n11, edges11, patches11 = ax11.hist(\n",
    "            track_mean_dQdx[p_mask],\n",
    "            bins=bins_all11,\n",
    "            label=rf\"p_value $\\leq {p_value_limit}$\",\n",
    "        )\n",
    "        ax12.hist(\n",
    "            track_length[p_mask],\n",
    "            bins=bins_all12,\n",
    "            label=rf\"p_value $\\leq {p_value_limit}$\",\n",
    "        )\n",
    "\n",
    "    ax11.set_xlabel(rf\"$dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "    ax11.set_title(f\"{len(track_mean_dQdx)} tracks\")\n",
    "    # last_index = (n_all11 < 2).argmax()\n",
    "    # print((n_all11 < 2))\n",
    "    # print((n_all11 < 2).argmax())\n",
    "    # ax11.set_xlim(-2, edges_all11[last_index])\n",
    "\n",
    "    ax12.set_title(f\"{len(track_length)} tracks\")\n",
    "\n",
    "    # 2D histograms\n",
    "    fig2 = plt.figure(figsize=(14, 6))\n",
    "    ax21 = fig2.add_subplot(121)\n",
    "\n",
    "    hist2d21 = ax21.hist2d(\n",
    "        track_length,\n",
    "        track_mean_dQdx,\n",
    "        bins=bins,\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )\n",
    "    ax21.set_ylabel(rf\"Mean $dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "    ax21.set_title(\"Mean dQ/dx vs. Track length\")\n",
    "\n",
    "    fit21 = np.polyfit(np.log(track_length), track_mean_dQdx, 1)\n",
    "\n",
    "    p21 = np.poly1d(fit21)\n",
    "    x2 = np.arange(min(track_length), max(track_length), 1)\n",
    "    ax21.plot(x2, p21(np.log(x2)), c=\"salmon\", ls=\"-\", label=\"Log fit\")\n",
    "\n",
    "    ax22 = fig2.add_subplot(122)\n",
    "\n",
    "    hist2d22 = ax22.hist2d(\n",
    "        track_length,\n",
    "        track_cv_dQdx,\n",
    "        bins=bins,\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )\n",
    "    ax22.set_ylabel(rf\"$dQ/dx$ CV\")\n",
    "    ax22.set_title(\"dQ/dx CV vs. Track length\")\n",
    "\n",
    "    fit22 = np.polyfit(np.log(track_length), track_cv_dQdx, 1)\n",
    "\n",
    "    p22 = np.poly1d(fit22)\n",
    "    ax22.plot(x2, p22(np.log(x2)), c=\"salmon\", ls=\"-\", label=\"Log fit\")\n",
    "\n",
    "    fig2.suptitle(f\"{len(track_mean_dQdx)} tracks\")\n",
    "\n",
    "    axes = [ax11, ax12, ax21, ax22]\n",
    "    figs = [fig1, fig2]\n",
    "\n",
    "    fig4 = plt.figure(figsize=(7, 6))\n",
    "    figs.append(fig4)\n",
    "\n",
    "    ax4 = fig4.add_subplot(111)\n",
    "    axes.append(ax4)\n",
    "\n",
    "    hist2d4 = ax4.hist2d(\n",
    "        track_length,\n",
    "        track_p_value,\n",
    "        bins=[bins[0], 40],\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )  # , cmin=1, bins = 15)\n",
    "    ax4.set_ylabel(f\"Fit p_value\")\n",
    "    ax4.set_title(\"Fit p_value vs. Track length\")\n",
    "\n",
    "    cut_dQdx_series = pd.concat(\n",
    "        [series for i, series in enumerate(dQdx_list) if p_mask[i]]\n",
    "    )\n",
    "    cut_dQdx_series = cut_dQdx_series[cut_dQdx_series > 0].dropna().sort_index()\n",
    "    dQdx_series = pd.concat(dQdx_list)\n",
    "    dQdx_series = dQdx_series[dQdx_series > 0].dropna().sort_index()\n",
    "\n",
    "    fig5 = plt.figure(figsize=(7 + 7 * p_bool, 6))\n",
    "    figs.append(fig5)\n",
    "    ax51 = fig5.add_subplot(111 + 10 * p_bool)\n",
    "    axes.append(ax51)\n",
    "\n",
    "    ax51.hist2d(\n",
    "        dQdx_series.index,\n",
    "        dQdx_series,\n",
    "        bins=bins,\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )\n",
    "    fit51 = np.polyfit(dQdx_series.index, dQdx_series, 1)\n",
    "    p51 = np.poly1d(fit51)\n",
    "    ax51.plot(\n",
    "        dQdx_series.index,\n",
    "        p51(dQdx_series.index),\n",
    "        c=\"salmon\",\n",
    "        ls=\"-\",\n",
    "        label=f\"Linear fit\",\n",
    "    )\n",
    "    ax51.set_ylabel(rf\"$dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "    ax51.set_xlabel(rf\"Residual range [{dh_unit}]\")\n",
    "    ax51.set_title(rf\"{len(track_mean_dQdx)} tracks\")\n",
    "\n",
    "    if p_bool:\n",
    "        # 2D histograms after p_value cut\n",
    "        fig3 = plt.figure(figsize=(14, 6))\n",
    "        figs.append(fig3)\n",
    "\n",
    "        ax31 = fig3.add_subplot(121)\n",
    "        ax32 = fig3.add_subplot(122)\n",
    "        axes.extend([ax31, ax32])\n",
    "\n",
    "        hist2d31 = ax31.hist2d(\n",
    "            track_length[p_mask],\n",
    "            track_mean_dQdx[p_mask],\n",
    "            bins=bins,\n",
    "            cmin=1,\n",
    "            norm=LogNorm() if lognorm else None,\n",
    "        )  # , cmin=1, bins = 15)\n",
    "        ax31.set_ylabel(rf\"Mean $dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "\n",
    "        fit31 = np.polyfit(np.log(track_length[p_mask]), track_mean_dQdx[p_mask], 1)\n",
    "        p31 = np.poly1d(fit31)\n",
    "        x3 = np.arange(min(track_length[p_mask]), max(track_length[p_mask]), 1)\n",
    "        ax31.plot(x3, p31(np.log(x3)), c=\"salmon\", ls=\"-\", label=\"Log fit\")\n",
    "        ax31.set_title(rf\"Mean dQ/dx vs. Track length\")\n",
    "\n",
    "        hist2d32 = ax32.hist2d(\n",
    "            track_length[p_mask],\n",
    "            track_cv_dQdx[p_mask],\n",
    "            bins=bins,\n",
    "            cmin=1,\n",
    "            norm=LogNorm() if lognorm else None,\n",
    "        )  # , cmin=1, bins = 15)\n",
    "        ax32.set_ylabel(rf\"$dQ/dx$ CV\")\n",
    "\n",
    "        fit32 = np.polyfit(np.log(track_length[p_mask]), track_cv_dQdx[p_mask], 1)\n",
    "        p32 = np.poly1d(fit32)\n",
    "        ax32.plot(x3, p32(np.log(x3)), c=\"salmon\", ls=\"-\", label=\"Log fit\")\n",
    "        ax32.set_title(rf\"dQ/dx CV vs. Track length\")\n",
    "\n",
    "        fig3.suptitle(\n",
    "            rf\"Fit p_value $\\leq {p_value_limit}$ ({round(sum(p_mask)/len(p_mask)*100)}% of tracks)\"\n",
    "        )\n",
    "\n",
    "        ax52 = fig5.add_subplot(122)\n",
    "        axes.append(ax52)\n",
    "\n",
    "        ax52.hist2d(\n",
    "            cut_dQdx_series.index,\n",
    "            cut_dQdx_series,\n",
    "            bins=bins,\n",
    "            cmin=1,\n",
    "            norm=LogNorm() if lognorm else None,\n",
    "        )\n",
    "        fit52 = np.polyfit(cut_dQdx_series.index, cut_dQdx_series, 1)\n",
    "        p52 = np.poly1d(fit52)\n",
    "        ax52.plot(\n",
    "            cut_dQdx_series.index,\n",
    "            p52(cut_dQdx_series.index),\n",
    "            c=\"salmon\",\n",
    "            ls=\"-\",\n",
    "            label=f\"Linear fit\",\n",
    "        )\n",
    "        ax52.set_ylabel(rf\"$dQ/dx$ [{q_unit} {dh_unit}$^{{-1}}$]\")\n",
    "        ax52.set_xlabel(rf\"Residual range [{dh_unit}]\")\n",
    "        ax52.set_title(\n",
    "            rf\"Fit p_value $\\leq {p_value_limit}$ ({round(sum(p_mask)/len(p_mask)*100)}% of tracks)\"\n",
    "        )\n",
    "\n",
    "    max_track_legth = np.sqrt(detector_x**2 + detector_y**2 + detector_z**2)\n",
    "    max_track_legth_xy = np.sqrt(detector_x**2 + detector_y**2)\n",
    "    print(\"Max possible track length\", round(max_track_legth, 2), \"mm\")\n",
    "    print(\"Max possible track lengt on xy plane\", round(max_track_legth_xy, 2), \"mm\")\n",
    "    print(\"Max possible vertical track length\", detector_y, \"mm\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=not (ax == ax4)))\n",
    "        ax.tick_params(\n",
    "            axis=\"both\", direction=\"inout\", which=\"major\", right=True, top=True\n",
    "        )\n",
    "        if ax == ax11 or ax == ax12:\n",
    "            ax.set_ylabel(\"Counts\")\n",
    "        if ax != ax11:\n",
    "            if not (ax == ax51 or (p_bool and ax == ax52)):\n",
    "                ax.set_xlabel(f\"Track length [{dh_unit}]\")\n",
    "            if max(track_length) > detector_y:\n",
    "                ax.axvline(detector_y, c=\"g\", ls=\"--\", label=\"Max vertical length\")\n",
    "            if max(track_length) > max_track_legth_xy:\n",
    "                ax.axvline(\n",
    "                    max_track_legth_xy, c=\"orange\", ls=\"--\", label=r\"Max length in $xy$\"\n",
    "                )\n",
    "            if max(track_length) > max_track_legth:\n",
    "                ax.axvline(max_track_legth, c=\"r\", ls=\"--\", label=\"Max length\")\n",
    "\n",
    "            if ax != ax12:\n",
    "                if limit_xrange:\n",
    "                    xlim = ax.get_xlim()\n",
    "                    ax.set_xlim(xlim[0], min(max_track_legth + 10, xlim[1]))\n",
    "                cbar = plt.colorbar(ax.collections[0])\n",
    "                cbar.set_label(\"Counts [Log]\")\n",
    "        if not (not p_bool and ax == ax11):\n",
    "            ax.legend(loc=\"upper right\")\n",
    "\n",
    "    for fig in figs:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    entries = len(track_mean_dQdx)\n",
    "\n",
    "    fig1.savefig(f\"track_stats_1D_hist_{file_label}_{entries}.png\", dpi=300)\n",
    "    fig2.savefig(f\"track_stats_2D_hist_{file_label}_{entries}.png\", dpi=300)\n",
    "    fig4.savefig(f\"track_stats_p_value_{file_label}_{entries}.png\", dpi=300)\n",
    "    fig5.savefig(f\"track_stats_dQdx_{file_label}_{entries}.png\", dpi=300)\n",
    "    if p_bool:\n",
    "        fig3.savefig(f\"track_stats_2D_hist_cut_{file_label}_{entries}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_light_geo_stats(\n",
    "    metrics,\n",
    "    limit_xrange=False,\n",
    "    min_count_ratio=0.99,\n",
    "    max_std_ratio=0.2,\n",
    "    single_track=True,\n",
    "    lognorm=True,\n",
    "):\n",
    "    sipm_distance = []\n",
    "    sipm_angle = []\n",
    "    sipm_light = []\n",
    "    sipm_charge = []\n",
    "    non_track_keys = 4\n",
    "\n",
    "    for event_idx, metric in metrics.items():\n",
    "        if single_track and len(metric.keys()) > 1 + non_track_keys:\n",
    "            continue\n",
    "        for track_idx, values in metric.items():\n",
    "            if not isinstance(track_idx, str) and track_idx > 0:\n",
    "                track_charge = sum(values[\"dQ\"]) / values[\"q_eff\"]\n",
    "                sipm_distance.extend(values[\"Light_distance\"].values())\n",
    "                sipm_angle.extend(values[\"Light_angle\"].values())\n",
    "                sipm_light.extend(values[f\"Light_{light_variable}\"].values())\n",
    "                sipm_charge.extend(np.full(len(values[\"Light_angle\"]), track_charge))\n",
    "\n",
    "    sipm_distance = np.array(sipm_distance)\n",
    "    sipm_angle = np.array(sipm_angle)\n",
    "    sipm_charge = np.array(sipm_charge)\n",
    "    sipm_light = np.array(sipm_light)\n",
    "\n",
    "    max_distance = np.sqrt(detector_x**2 + detector_y**2 + detector_z**2)\n",
    "    print(\"Max possible distance to track\", round(max_distance, 2), \"mm\")\n",
    "    print(\"Drift distance\", detector_z, \"mm\")\n",
    "\n",
    "    # if limit_xrange:\n",
    "    #     sipm_distance = sipm_distance[sipm_distance <= max_distance]\n",
    "    #     sipm_angle = sipm_angle[sipm_distance <= max_distance]\n",
    "    #     sipm_charge = sipm_charge[sipm_distance <= max_distance]\n",
    "    #     sipm_light = sipm_light[sipm_distance <= max_distance]\n",
    "\n",
    "    sipm_distance = sipm_distance[~np.isnan(sipm_light) & (sipm_light > 0)]\n",
    "    sipm_angle = sipm_angle[~np.isnan(sipm_light) & (sipm_light > 0)]\n",
    "    sipm_charge = sipm_charge[~np.isnan(sipm_light) & (sipm_light > 0)]\n",
    "    sipm_light = sipm_light[~np.isnan(sipm_light) & (sipm_light > 0)]\n",
    "\n",
    "    fig1 = plt.figure(figsize=(7, 6))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    axes = np.array(ax1)\n",
    "\n",
    "    vline = max_std(\n",
    "        sipm_light,\n",
    "        ax1,\n",
    "        array_max=100,\n",
    "        max_std_ratio=max_std_ratio,\n",
    "        min_count_ratio=min_count_ratio,\n",
    "    )\n",
    "    bins = vline\n",
    "\n",
    "    ax1.set_xlabel(\"Max light integral\")\n",
    "    ax1.set_ylabel(\"Normalized value\")\n",
    "\n",
    "    fig1.suptitle(\"Light integral distribution\")\n",
    "\n",
    "    sipm_distance = sipm_distance[(sipm_light <= vline)]\n",
    "    sipm_angle = sipm_angle[(sipm_light <= vline)]\n",
    "    sipm_charge = sipm_charge[(sipm_light <= vline)]\n",
    "    sipm_light = sipm_light[(sipm_light <= vline)]\n",
    "    sipm_angle = np.degrees(sipm_angle)\n",
    "\n",
    "    fig2, ax2 = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    axes = np.append(axes, ax2)\n",
    "\n",
    "    hist2 = ax2.hist2d(\n",
    "        sipm_distance,\n",
    "        sipm_angle,\n",
    "        weights=abs(sipm_light),\n",
    "        bins=bins,\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )\n",
    "    def fit_function(x, a, b):\n",
    "        return 1/(a * x + b)\n",
    "    parameters, cov_matrix = curve_fit(\n",
    "                    fit_function,\n",
    "                    sipm_distance,\n",
    "                    sipm_angle,\n",
    "                )\n",
    "    print(latexify.get_latex(fit_function))\n",
    "    print(\"Parameters:\")\n",
    "    print(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                f\"{name}: {value}\"\n",
    "                for name, value in zip(\n",
    "                    [\"a\", \"b\"], parameters\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    x2 = np.arange(min(sipm_distance), max(sipm_distance), 1)\n",
    "    ax2.plot(x2,fit_function(x2, *parameters), c=\"salmon\", ls=\"-\", label=rf\"$1/x$ fit\")\n",
    "    cbar2 = plt.colorbar(hist2[3])\n",
    "    cbar2.set_label(rf\"Light {light_variable} [{light_unit} - log]\")\n",
    "\n",
    "    ax2.set_ylabel(f\"SiPM opening angle to track centre [deg]\")\n",
    "\n",
    "    fig2.suptitle(f\"SiPM level light distribution - {len(sipm_light)} entries\")\n",
    "\n",
    "    fig3, axes3 = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    axes = np.append(axes, axes3)\n",
    "\n",
    "    hist30 = axes3[0].hist2d(\n",
    "        sipm_distance,\n",
    "        sipm_light,\n",
    "        bins=bins,\n",
    "        cmin=1,\n",
    "        norm=LogNorm() if lognorm else None,\n",
    "    )\n",
    "    axes3[0].set_ylabel(f\"Light_{light_variable} [{light_unit}]\")\n",
    "\n",
    "    cbar30 = plt.colorbar(hist30[3])\n",
    "    cbar30.set_label(rf\"Counts [Log]\")\n",
    "\n",
    "    hist31 = axes3[1].hist2d(\n",
    "        sipm_angle, sipm_light, bins=bins, cmin=1, norm=LogNorm() if lognorm else None\n",
    "    )\n",
    "    axes3[1].set_xlabel(f\"SiPM opening angle to track [deg]\")\n",
    "    axes3[1].set_ylabel(f\"Light {light_variable} [{light_unit}]\")\n",
    "    cbar31 = plt.colorbar(hist31[3])\n",
    "    cbar31.set_label(rf\"Counts [Log]\")\n",
    "\n",
    "    fig3.suptitle(f\"SiPM level light distribution - {len(sipm_light)} entries\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        if not ax == ax1:\n",
    "            ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "        ax.tick_params(axis=\"both\", direction=\"inout\", which=\"major\", top=True)\n",
    "        if ax == ax2 or ax == axes3[0]:\n",
    "            if limit_xrange:\n",
    "                xlim = ax.get_xlim()\n",
    "                ax.set_xlim(xlim[0], min(max_distance + 10, xlim[1]))\n",
    "            if max(sipm_distance) > detector_z:\n",
    "                ax.axvline(detector_z, c=\"orange\", ls=\"--\", label=\"Drift distance\")\n",
    "            if max(sipm_distance) > max_distance:\n",
    "                ax.axvline(max_distance, c=\"r\", ls=\"--\", label=\"Max distance\")\n",
    "\n",
    "            ax.set_xlabel(f\"Distance from track centre [{dh_unit}]\")\n",
    "\n",
    "            ax.legend()\n",
    "\n",
    "    for fig in [fig1, fig2, fig3]:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    entries = len(sipm_light)\n",
    "    fig1.savefig(f\"light_geo_optimization_{file_label}_{entries}.png\", dpi=300)\n",
    "    fig2.savefig(f\"light_geo_2D_hist_{file_label}_{entries}.png\", dpi=300)\n",
    "    fig3.savefig(f\"light_geo_1D_hist_{file_label}_{entries}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_vs_charge(\n",
    "    metrics,\n",
    "    min_count_ratio=0.99,\n",
    "    max_std_ratio=0.5,\n",
    "    clusters=None,\n",
    "    bin_density=1,\n",
    "    log=(True, False),\n",
    "):\n",
    "    if isinstance(log, bool):\n",
    "        log = [log, log]\n",
    "\n",
    "    light_array = []\n",
    "    charge_array = []\n",
    "    for event, metric in metrics.items():\n",
    "        light_array.append(metric[\"Total_light\"])\n",
    "        charge_array.append(metric[\"Total_charge\"])\n",
    "\n",
    "    light_array = np.array(light_array)\n",
    "    charge_array = np.array(charge_array)\n",
    "\n",
    "    mask = (charge_array > 0) & (light_array > 0)\n",
    "    charge_array = charge_array[mask]\n",
    "    light_array = light_array[mask]\n",
    "\n",
    "    fig1 = plt.figure(figsize=(8, 6))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.set_xlabel(\"Max light integral\")\n",
    "    ax1.set_ylabel(\"Normalized value\")\n",
    "    fig1.suptitle(\"Light integral distribution\")\n",
    "    vline = max_std(\n",
    "        light_array,\n",
    "        ax1,\n",
    "        array_max=1000,\n",
    "        min_count_ratio=min_count_ratio,\n",
    "        max_std_ratio=max_std_ratio,\n",
    "    )\n",
    "    bins = int(vline / 20)\n",
    "\n",
    "    charge_array = charge_array[(light_array <= vline)]\n",
    "    light_array = light_array[(light_array <= vline)]\n",
    "\n",
    "    def hist2d(x, y, ax, bins, log):\n",
    "        if log:\n",
    "            log_bins_x = np.exp(np.linspace(np.log(min(x) - 1), np.log(max(x)), bins))\n",
    "            log_bins_y = np.exp(np.linspace(np.log(min(y)), np.log(max(y)), bins))\n",
    "            bins = [log_bins_x, log_bins_y]\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        hist = ax.hist2d(x, y, bins=bins, cmin=1)\n",
    "\n",
    "        ax.set_xlabel(f\"Event total charge [{q_unit}{' - Log' if log else ''}]\")\n",
    "        ax.set_ylabel(f\"Light {light_variable} [{light_unit}{' - Log' if log else ''}]\")\n",
    "        ax.tick_params(axis=\"both\", direction=\"inout\", which=\"major\", top=True)\n",
    "\n",
    "        cbar = plt.colorbar(hist[3])\n",
    "        cbar.set_label(rf\"Counts\")\n",
    "        if not log:\n",
    "            ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "            ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    def hist1d(array, ax, bin_density, log):\n",
    "        # fit peak with curve_fit\n",
    "        # @latexify.function(use_math_symbols=True)\n",
    "        def fit_function(x, a, mu, sigma, b, c):\n",
    "            return (\n",
    "                # gaussian_part\n",
    "                a\n",
    "                * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "                / (sigma * np.sqrt(2 * np.pi))\n",
    "                # exponential_part\n",
    "                + b * np.exp(-c * (x - mu))\n",
    "            )\n",
    "\n",
    "        upper_bound = np.percentile(array, 95)\n",
    "        array = array[array < upper_bound]\n",
    "        if log:\n",
    "            ax.set_xscale(\"log\")\n",
    "            bins = np.exp(\n",
    "                np.linspace(\n",
    "                    np.log(min(array) - 1), np.log(max(array)), int(50 * bin_density)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            bins = np.linspace(0, upper_bound, int(50 * bin_density))\n",
    "\n",
    "        n, edges, patches = ax.hist(\n",
    "            array, bins=bins, fill=False, ec=\"C0\", histtype=\"bar\"\n",
    "        )\n",
    "\n",
    "        peak_y = n.max()\n",
    "        peak_x = edges[n.argmax() : n.argmax() + 1].mean()\n",
    "        mean = array.mean()\n",
    "        median = np.median(array)\n",
    "\n",
    "        if not log:\n",
    "            ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "            ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "            bin_centers = 0.5 * (edges[1:] + edges[:-1])\n",
    "            bin_centers = bin_centers[n > 0]\n",
    "            bin_peaks = n[n > 0]\n",
    "            try:\n",
    "                parameters, cov_matrix = curve_fit(\n",
    "                    fit_function,\n",
    "                    bin_centers / min(bin_centers),\n",
    "                    bin_peaks,\n",
    "                    p0=[0.1, peak_x / min(bin_centers), 0.1, 0, 0.1],\n",
    "                )\n",
    "                x_plot = np.linspace(edges[0], edges[-1], len(bins * 2))\n",
    "                y_plot = fit_function(x_plot / min(bin_centers), *parameters)\n",
    "\n",
    "                print(latexify.get_latex(fit_function))\n",
    "                print(\"Parameters:\")\n",
    "                print(\n",
    "                    \"\\n\".join(\n",
    "                        [\n",
    "                            f\"{name}: {value}\"\n",
    "                            for name, value in zip(\n",
    "                                [\"a\", \"mu\", \"sigma\", \"b\", \"c\"], parameters\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                ax.plot(\n",
    "                    x_plot,\n",
    "                    y_plot,\n",
    "                    \"m\",\n",
    "                    label=rf\"Fit ($\\mu={parameters[1]*min(bin_centers):.2f}$)\",\n",
    "                )\n",
    "            except:\n",
    "                print(\"Fit failed\")\n",
    "\n",
    "        ax.axvline(peak_x, c=\"r\", ls=\"--\", label=f\"Peak: {peak_x:.2f}\")\n",
    "        ax.axvline(median, c=\"orange\", ls=\"--\", label=f\"Median: {median:.2f}\")\n",
    "        ax.axvline(mean, c=\"g\", ls=\"--\", label=f\"Mean: {mean:.2f}\")\n",
    "\n",
    "        ax.set_ylabel(f\"Counts\")\n",
    "        # ax.set_xlim(min(array) - 2, edges3[(edges3 < upper_bound).argmin()])\n",
    "        ax.tick_params(axis=\"both\", direction=\"inout\", which=\"major\", top=True)\n",
    "        ax.legend()\n",
    "\n",
    "    fig2 = plt.figure(figsize=(8, 6))\n",
    "    ax2 = plt.subplot(111)\n",
    "    hist2d(charge_array, light_array, ax2, bins, log[0])\n",
    "    fig2.suptitle(f\"Event level Light vs. Charge - {len(charge_array)} events\")\n",
    "\n",
    "    fig3 = plt.figure(figsize=(8, 6))\n",
    "    ax3 = plt.subplot(111)\n",
    "    ratio = charge_array / light_array\n",
    "    hist1d(ratio, ax3, bin_density, log[1])\n",
    "    ax3.set_xlabel(f\"Event total charge / Light [{q_unit}/{light_unit}{' - Log' if log[1] else ''}]\")\n",
    "    fig3.suptitle(f\"Event level Charge vs. Light - {len(charge_array)} events\")\n",
    "\n",
    "    fig4, axes4 = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    hist1d(charge_array, axes4[0], bin_density, log[1])\n",
    "    axes4[0].set_xlabel(f\"Event total charge [{q_unit}{' - Log' if log[1] else ''}]\")\n",
    "    hist1d(light_array, axes4[1], bin_density, log[1])\n",
    "    axes4[1].set_xlabel(f\"Event total Light [{light_unit}{' - Log' if log[1] else ''}]\")\n",
    "\n",
    "    figs = [fig1, fig2, fig3, fig4]\n",
    "\n",
    "    if not clusters is None:\n",
    "        data = pd.DataFrame(np.log(charge_array), np.log(light_array))\n",
    "        kmeans = KMeans(n_clusters=clusters)\n",
    "        kmeans.fit(data)\n",
    "        labels = kmeans.predict(data) + 1\n",
    "        populations = np.unique(labels)\n",
    "\n",
    "        fig22, axes22 = plt.subplots(\n",
    "            len(populations), 1, figsize=(8, 6 * len(populations))\n",
    "        )\n",
    "\n",
    "        fig32, axes32 = plt.subplots(\n",
    "            len(populations), 1, figsize=(10, 6 * len(populations))\n",
    "        )\n",
    "\n",
    "        figs.extend([fig22, fig32])\n",
    "\n",
    "        for idx, label in enumerate(populations):\n",
    "            hist2d(\n",
    "                charge_array[labels == label],\n",
    "                light_array[labels == label],\n",
    "                axes22[idx],\n",
    "                bins,\n",
    "                log[0],\n",
    "            )\n",
    "            axes22[idx].set_title(f\"Population {label} - {sum(labels == label)} events\")\n",
    "\n",
    "            print(f\"population {label}:\")\n",
    "\n",
    "            ratio = charge_array[labels == label] / light_array[labels == label]\n",
    "            hist1d(ratio, axes32[idx], bin_density, log[1])\n",
    "            axes32[idx].set_xlabel(f\"Event total charge / Light [{q_unit}/{light_unit}{' - Log' if log[1] else ''}]\")\n",
    "            axes32[idx].set_title(f\"Population {label} - {sum(labels == label)} events\")\n",
    "\n",
    "    for fig in figs:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    events = len(ratio)\n",
    "    fig1.savefig(f\"light_vs_charge_optmization_{file_label}_{events}.png\", dpi=300)\n",
    "    fig2.savefig(f\"light_vs_charge_2D_hist_{file_label}_{events}.png\", dpi=300)\n",
    "    fig3.savefig(f\"light_vs_charge_ratio_{file_label}_{events}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If match dictionary already exists for this file label, load it\n",
    "if not rematch_events and os.path.isfile(f\"match_dict_{file_label}.json\"):\n",
    "    with open(f\"match_dict_{file_label}.json\", \"r\") as f:\n",
    "        match_dict = json.load(f)\n",
    "        match_dict = {int(key): value for key, value in match_dict.items()}\n",
    "\n",
    "    print(\"Match_dict loaded from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reload_file and os.path.isfile(f\"charge_df_{file_label}.bz2\"):\n",
    "    charge_df = pd.read_csv(f\"charge_df_{file_label}.bz2\", index_col=0)\n",
    "    if not event_list is None:\n",
    "        charge_df = charge_df.loc[event_list.intersection(charge_df.index)]\n",
    "    # for column in :\n",
    "    charge_df[charge_df.columns[9:]] = charge_df[charge_df.columns[9:]].applymap(\n",
    "        lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    "    )\n",
    "else:\n",
    "    charge_df = load_charge(charge_file, events=event_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up charge dataframe\n",
    "\n",
    "# Remove events with negative charge hits and without light trigger\n",
    "charge_mask = (\n",
    "    charge_df[\"event_hits_q\"].apply(tuple).explode().groupby(\"eventID\").min() > 0\n",
    ") * (charge_df[\"trigID\"].apply(len) > 0)\n",
    "charge_df = charge_df[charge_mask]\n",
    "\n",
    "print(\n",
    "    f\"Removed charge events: {charge_mask.count()-charge_mask.sum()}/{charge_mask.count()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If match dictionary already loaded, match loaded charge events to light events before loading light events.\n",
    "light_event_list = None\n",
    "if not match_dict == {}:\n",
    "    light_event_list = ak.flatten(\n",
    "        [\n",
    "            match_dict.get(event, [])\n",
    "            for event in charge_df.index\n",
    "            if event_list is None or event in event_list\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(f\"{len(light_event_list)} light events to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load light events using light_event_list if loaded via match dictionary\n",
    "if not reload_file and os.path.isfile(f\"light_df_{file_label}.bz2\"):\n",
    "    light_df = pd.read_csv(f\"light_df_{file_label}.bz2\", index_col=0)\n",
    "    if not light_event_list is None:\n",
    "        light_df = light_df[light_df[\"event\"].isin(light_event_list)]\n",
    "\n",
    "else:\n",
    "    light_df = load_light(\n",
    "        light_file, deco=\"deco\" in light_file, events=light_event_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up light dataframe\n",
    "\n",
    "# If match dictionary not yet loaded, create it\n",
    "if match_dict == {} or rematch_events:\n",
    "    match_dict = match_events(charge_df, light_df)\n",
    "\n",
    "    # Remove light events without charge event match\n",
    "    light_events = np.unique(ak.flatten(match_dict.values()))\n",
    "    light_df = light_df[light_df[\"event\"].isin(light_events)]\n",
    "\n",
    "    print(\n",
    "        f\"Remaining light events with charge event match: {light_df['event'].nunique()}\"\n",
    "    )\n",
    "\n",
    "# Remove charge events without associated light event\n",
    "charge_df = charge_df.loc[match_dict.keys()]\n",
    "\n",
    "print(f\"Remaining charge events with light match: {len(charge_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save files if all events were considered, i.e. event_list is None\n",
    "if event_list is None:\n",
    "    charge_df.to_csv(f\"charge_df_{file_label}.bz2\")\n",
    "    light_df.to_csv(f\"light_df_{file_label}.bz2\")\n",
    "    with open(f\"match_dict_{file_label}.json\", \"w\") as f:\n",
    "        json.dump(match_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trigger time distribution\")\n",
    "charge_df[\"trig_time\"].apply(np.mean).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Event duration in {time_unit}\")\n",
    "charge_df[\"event_duration\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Charge per hit in {q_unit}\")\n",
    "(charge_df[\"event_q\"] / charge_df[\"event_nhits\"]).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Charge per hit per event in {q_unit}\")\n",
    "(charge_df[\"event_q\"] / charge_df[\"event_nhits\"]).to_frame().reset_index().plot.scatter(\n",
    "    x=\"eventID\", y=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Event charge in {q_unit}\")\n",
    "charge_df[\"event_q\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hits q in {q_unit}\")\n",
    "charge_df[\"event_hits_q\"].apply(tuple).explode().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hits z in {z_unit}\")\n",
    "charge_df[\"event_hits_z\"].apply(tuple).explode().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake data map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fake_data(z_range):\n",
    "    fake_data = generate_dead_area(z_range)\n",
    "    fake_x, fake_y, fake_z = fake_data[:, 0], fake_data[:, 1], fake_data[:, 2]\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.scatter(fake_x, fake_y, marker=\"s\", s=20)\n",
    "    ax.set_xlim([-detector_x / 2, detector_x / 2])\n",
    "    ax.set_ylim([-detector_y / 2, detector_y / 2])\n",
    "    ax.set_xlabel(f\"x [{xy_unit}]\")\n",
    "    ax.set_ylabel(f\"y [{xy_unit}]\")\n",
    "    ax.set_xticks(np.linspace(-detector_x / 2, detector_x / 2, 5))\n",
    "    ax.set_yticks(np.linspace(-detector_y / 2, detector_y / 2, 6))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(8))\n",
    "    ax.grid()\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", top=True, right=True)\n",
    "\n",
    "    fig.savefig(\"fake_data_map.png\", dpi=300)\n",
    "\n",
    "\n",
    "plot_fake_data(np.arange(-detector_z, 0, 10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "if event_list is None:\n",
    "    index_list = charge_df.index\n",
    "else:\n",
    "    index_list = charge_df.index.intersection(event_list)\n",
    "\n",
    "for idx in tqdm(index_list):\n",
    "    row = charge_df.loc[idx]\n",
    "\n",
    "    charge_channelid_array = np.array(row[\"event_hits_channelid\"])\n",
    "    charge_x_array = np.array(row[\"event_hits_x\"])\n",
    "    charge_y_array = np.array(row[\"event_hits_y\"])\n",
    "    charge_z_array = np.array(row[\"event_hits_z\"])\n",
    "    charge_time_array = np.array(row[\"event_hits_ts\"])\n",
    "    charge_array = np.array(row[\"event_hits_q\"])\n",
    "\n",
    "    non_zero_mask = (charge_x_array != 0) * (\n",
    "        charge_y_array != 0\n",
    "    )  # Remove (0,0) entries\n",
    "    noisy_channels_mask = np.isin(\n",
    "        charge_channelid_array, channel_disable_list, invert=True\n",
    "    )  # Disable channel 7\n",
    "    mask = non_zero_mask * noisy_channels_mask  # Full hits mask\n",
    "\n",
    "    # Apply boolean indexing to x, y, and z arrays\n",
    "    charge_x_array = charge_x_array[mask]\n",
    "    charge_y_array = charge_y_array[mask]\n",
    "    charge_z_array = charge_z_array[mask]\n",
    "    charge_time_array = charge_time_array[mask]\n",
    "    charge_array = charge_array[mask] * charge_gain  # Convert mV to ke\n",
    "\n",
    "    light_event = match_dict.get(idx, [idx])[0]\n",
    "    light_values = light_df[light_df[\"event\"] == light_event].dropna(\n",
    "        subset=light_variable\n",
    "    )\n",
    "    light_x_array = light_values[\"x\"]\n",
    "    light_y_array = light_values[\"y\"]\n",
    "    light_array = light_values[light_variable]\n",
    "\n",
    "    if len(charge_x_array) > 2:\n",
    "        if idx in individual_plots:\n",
    "            metrics[idx] = event_display(\n",
    "                idx,\n",
    "                charge_x_array,\n",
    "                charge_y_array,\n",
    "                charge_z_array,\n",
    "                charge_time_array,\n",
    "                charge_array,\n",
    "                light_x_array,\n",
    "                light_y_array,\n",
    "                light_array,\n",
    "                plot_cyl=False,\n",
    "            )\n",
    "            if show_figures:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "        else:\n",
    "            # Create a design matrix\n",
    "            xyz = np.c_[charge_x_array, charge_y_array, charge_z_array]\n",
    "            # Cluster the hits\n",
    "            labels = cluster(xyz)\n",
    "            # Fit clusters\n",
    "            metrics[idx] = fitClusters(xyz, charge_array, labels)\n",
    "\n",
    "        # Light metrics\n",
    "        for track_idx, values in metrics[idx].items():\n",
    "            if \"Fit_line\" not in values:\n",
    "                continue\n",
    "            light_metrics = light_geometry(\n",
    "                track_line=values[\"Fit_line\"],\n",
    "                track_norm=values[\"Fit_norm\"],\n",
    "                sipm_df=light_values,\n",
    "                light_variable=light_variable,\n",
    "            )\n",
    "\n",
    "            values[\"Light_distance\"] = light_metrics[\"Light_distance\"]\n",
    "            values[\"Light_angle\"] = light_metrics[\"Light_angle\"]\n",
    "            values[f\"Light_{light_variable}\"] = light_metrics[f\"Light_{light_variable}\"]\n",
    "\n",
    "        metrics[idx][\n",
    "            \"Pixel_mask\"\n",
    "        ] = mask  # Save masks to original dataframe for reference\n",
    "        metrics[idx][\"Total_light\"] = light_values[light_variable].sum()\n",
    "        metrics[idx][\"Total_charge\"] = charge_array.sum()\n",
    "\n",
    "    # else:\n",
    "    #     print(f\"Event {idx}: Not enough hits to fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the warning filter (optional)\n",
    "warnings.filterwarnings(\"default\", category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the metrics to a pickle file\n",
    "# with open(f\"metrics_{file_label}.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(metrics, f)\n",
    "\n",
    "# print(f\"Metrics saved to metrics_{file_label}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics from pickle file\n",
    "with open(f\"metrics_{file_label}.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_metrics = metrics\n",
    "metrics = filter_metrics(\n",
    "    metrics,\n",
    "    p_value_limit=p_value_limit,\n",
    "    min_track_length=min_track_length,\n",
    "    max_tracks=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dQ/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_track_stats(\n",
    "    metrics,\n",
    "    limit_xrange=False,\n",
    "    empty_ratio_lims=(0.0, 1),\n",
    "    lognorm=True,\n",
    "    min_entries=2,\n",
    "    p_value_limit=1,\n",
    "    bins=[40, 40],\n",
    ")\n",
    "if show_figures:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_idx in tqdm(individual_plots, leave=False):\n",
    "    if event_idx in metrics:\n",
    "        for track_idx, values in metrics[event_idx].items():\n",
    "            if not isinstance(track_idx, str) and track_idx > 0:\n",
    "                dQ_array = values[\"dQ\"]\n",
    "                dh = values[\"dx\"]\n",
    "                plot_dQ(dQ_array, event_idx, track_idx, dh, interpolate=False)\n",
    "\n",
    "                if show_figures:\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_light_geo_stats(metrics, single_track=True, limit_xrange=True, lognorm=True)\n",
    "if show_figures:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_vs_charge(metrics, clusters=None, bin_density=1, log=(True, False))\n",
    "\n",
    "if show_figures:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light wave forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"rwf\" in light_df.columns:\n",
    "    for event_idx in tqdm(individual_plots, leave=True):\n",
    "        values = light_df[\n",
    "            (light_df[\"event\"] == match_dict.get(event_idx, [event_idx])[0])\n",
    "        ].sort_values(by=[\"sn\", \"ch\"])\n",
    "        for row_idx, row in values.iterrows():\n",
    "            ch_idx = row[\"ch\"]\n",
    "            sn_idx = row[\"sn\"]\n",
    "            rwf = row[\"rwf\"]\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.subplot(111)\n",
    "\n",
    "            fig.suptitle(f\"Event {event_idx} - ADC {sn_idx} - Channel {ch_idx}\")\n",
    "            ax.plot(rwf[:-1])\n",
    "            ax.axhline(np.median(rwf), ls=\"--\", c=\"red\")\n",
    "\n",
    "            ax.set_ylabel(f\"Light waveform [{light_unit}]\")\n",
    "            ax.set_xlabel(\"Time [Arbitrary units]\")\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            if show_figures:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
